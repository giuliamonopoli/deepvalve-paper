{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mRunning cells with 'test' requires the ipykernel package.\n",
                        "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
                        "\u001b[1;31mCommand: 'conda install -n test ipykernel --update-deps --force-reinstall'"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import os, cv2\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import random, tqdm\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "import segmentation_models_pytorch.utils as smp_utils\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "from dataset import heartdataset\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import DataLoader\n",
                "import albumentations as album\n",
                "import segmentation_models_pytorch as smp\n",
                "import utils\n",
                "import config\n",
                "from torchvision import models\n",
                "# Set seed for reproducibility\n",
                "utils.seed_everything(config.seed)\n",
                "\n",
                "\n",
                "# Set paths to train, val and test images and masks\n",
                "n_points = 30\n",
                "w_mask = 2\n",
                " \n",
                "path_for_segmentation_data_model=f'../../data/segmentation_data/segmentation_lines_{n_points}_{w_mask}' ## path for one of the trail,test,val folders to used in model \n",
                "x_test_dir=path_for_segmentation_data_model+'/test/images/'\n",
                "y_test_dir=path_for_segmentation_data_model+'/test/masks/'\n",
                "\n",
                "\n",
                "#x_test_dir = \"/Users/giuliamonopoli/Desktop/PhD /deepvalve/data/segmentation_data/segmentation_lines_30_2/val/images/\"\n",
                "#y_test_dir = \"/Users/giuliamonopoli/Desktop/PhD /deepvalve/data/segmentation_data/segmentation_lines_30_2/val/masks/\"\n",
                "#x_test_dir = \"/home/ashay/deepvale/data/segmentation_data/segmentation_lines_30_2/val/images/\"\n",
                "#y_test_dir = \"/home/ashay/deepvale/data/segmentation_data/segmentation_lines_30_2/val/masks/\"\n",
                "\n",
                "\n",
                "\n",
                "class_dict = pd.read_csv(config.labels)\n",
                "# Get class names\n",
                "class_names = class_dict['name'].tolist()\n",
                "# Get class RGB values\n",
                "class_rgb_values = class_dict[['r','g','b']].values.tolist()\n",
                "\n",
                "# print('All dataset classes and their corresponding RGB values in labels:')\n",
                "# print('Class Names: ', class_names)\n",
                "# print('Class RGB values: ', class_rgb_values)\n",
                "\n",
                "# Useful to shortlist specific classes in datasets with large number of classes\n",
                "select_classes = ['background', 'leaflet']\n",
                "\n",
                "# Get RGB values of required classes\n",
                "select_class_indices = [class_names.index(cls.lower()) for cls in select_classes]\n",
                "select_class_rgb_values =  np.array(class_rgb_values)[select_class_indices]\n",
                "\n",
                "# print('Selected classes and their corresponding RGB values in labels:')\n",
                "# print('Class Names: ', class_names)\n",
                "# print('Class RGB values: ', class_rgb_values)\n",
                "\n",
                "ENCODER = config.ENCODER\n",
                "ENCODER_WEIGHTS = config.ENCODER_WEIGHTS\n",
                "CLASSES = class_names\n",
                "ACTIVATION = config.ACTIVATION # could be None for logits or 'softmax2d' for multiclass segmentation\n",
                "\n",
                "# create segmentation model with pretrained encoder\n",
                "model = smp.Unet(\n",
                "    encoder_name=ENCODER,\n",
                "    encoder_weights=ENCODER_WEIGHTS,\n",
                "    classes=len(CLASSES),\n",
                "    activation=ACTIVATION,\n",
                ")\n",
                "\n",
                "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
                "model = model.to(\"cpu\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "ename": "RuntimeError",
                    "evalue": "Error(s) in loading state_dict for Unet:\n\tMissing key(s) in state_dict: \"encoder._conv_stem.weight\", \"encoder._bn0.weight\", \"encoder._bn0.bias\", \"encoder._bn0.running_mean\", \"encoder._bn0.running_var\", \"encoder._blocks.0._depthwise_conv.weight\", \"encoder._blocks.0._bn1.weight\", \"encoder._blocks.0._bn1.bias\", \"encoder._blocks.0._bn1.running_mean\", \"encoder._blocks.0._bn1.running_var\", \"encoder._blocks.0._se_reduce.weight\", \"encoder._blocks.0._se_reduce.bias\", \"encoder._blocks.0._se_expand.weight\", \"encoder._blocks.0._se_expand.bias\", \"encoder._blocks.0._project_conv.weight\", \"encoder._blocks.0._bn2.weight\", \"encoder._blocks.0._bn2.bias\", \"encoder._blocks.0._bn2.running_mean\", \"encoder._blocks.0._bn2.running_var\", \"encoder._blocks.1._depthwise_conv.weight\", \"encoder._blocks.1._bn1.weight\", \"encoder._blocks.1._bn1.bias\", \"encoder._blocks.1._bn1.running_mean\", \"encoder._blocks.1._bn1.running_var\", \"encoder._blocks.1._se_reduce.weight\", \"encoder._blocks.1._se_reduce.bias\", \"encoder._blocks.1._se_expand.weight\", \"encoder._blocks.1._se_expand.bias\", \"encoder._blocks.1._project_conv.weight\", \"encoder._blocks.1._bn2.weight\", \"encoder._blocks.1._bn2.bias\", \"encoder._blocks.1._bn2.running_mean\", \"encoder._blocks.1._bn2.running_var\", \"encoder._blocks.2._expand_conv.weight\", \"encoder._blocks.2._bn0.weight\", \"encoder._blocks.2._bn0.bias\", \"encoder._blocks.2._bn0.running_mean\", \"encoder._blocks.2._bn0.running_var\", \"encoder._blocks.2._depthwise_conv.weight\", \"encoder._blocks.2._bn1.weight\", \"encoder._blocks.2._bn1.bias\", \"encoder._blocks.2._bn1.running_mean\", \"encoder._blocks.2._bn1.running_var\", \"encoder._blocks.2._se_reduce.weight\", \"encoder._blocks.2._se_reduce.bias\", \"encoder._blocks.2._se_expand.weight\", \"encoder._blocks.2._se_expand.bias\", \"encoder._blocks.2._project_conv.weight\", \"encoder._blocks.2._bn2.weight\", \"encoder._blocks.2._bn2.bias\", \"encoder._blocks.2._bn2.running_mean\", \"encoder._blocks.2._bn2.running_var\", \"encoder._blocks.3._expand_conv.weight\", \"encoder._blocks.3._bn0.weight\", \"encoder._blocks.3._bn0.bias\", \"encoder._blocks.3._bn0.running_mean\", \"encoder._blocks.3._bn0.running_var\", \"encoder._blocks.3._depthwise_conv.weight\", \"encoder._blocks.3._bn1.weight\", \"encoder._blocks.3._bn1.bias\", \"encoder._blocks.3._bn1.running_mean\", \"encoder._blocks.3._bn1.running_var\", \"encoder._blocks.3._se_reduce.weight\", \"encoder._blocks.3._se_reduce.bias\", \"encoder._blocks.3._se_expand.weight\", \"encoder._blocks.3._se_expand.bias\", \"encoder._blocks.3._project_conv.weight\", \"encoder._blocks.3._bn2.weight\", \"encoder._blocks.3._bn2.bias\", \"encoder._blocks.3._bn2.running_mean\", \"encoder._blocks.3._bn2.running_var\", \"encoder._blocks.4._expand_conv.weight\", \"encoder._blocks.4._bn0.weight\", \"encoder._blocks.4._bn0.bias\", \"encoder._blocks.4._bn0.running_mean\", \"encoder._blocks.4._bn0.running_var\", \"encoder._blocks.4._depthwise_conv.weight\", \"encoder._blocks.4._bn1.weight\", \"encoder._blocks.4._bn1.bias\", \"encoder._blocks.4._bn1.running_mean\", \"encoder._blocks.4._bn1.running_var\", \"encoder._blocks.4._se_reduce.weight\", \"encoder._blocks.4._se_reduce.bias\", \"encoder._blocks.4._se_expand.weight\", \"encoder._blocks.4._se_expand.bias\", \"encoder._blocks.4._project_conv.weight\", \"encoder._blocks.4._bn2.weight\", \"encoder._blocks.4._bn2.bias\", \"encoder._blocks.4._bn2.running_mean\", \"encoder._blocks.4._bn2.running_var\", \"encoder._blocks.5._expand_conv.weight\", \"encoder._blocks.5._bn0.weight\", \"encoder._blocks.5._bn0.bias\", \"encoder._blocks.5._bn0.running_mean\", \"encoder._blocks.5._bn0.running_var\", \"encoder._blocks.5._depthwise_conv.weight\", \"encoder._blocks.5._bn1.weight\", \"encoder._blocks.5._bn1.bias\", \"encoder._blocks.5._bn1.running_mean\", \"encoder._blocks.5._bn1.running_var\", \"encoder._blocks.5._se_reduce.weight\", \"encoder._blocks.5._se_reduce.bias\", \"encoder._blocks.5._se_expand.weight\", \"encoder._blocks.5._se_expand.bias\", \"encoder._blocks.5._project_conv.weight\", \"encoder._blocks.5._bn2.weight\", \"encoder._blocks.5._bn2.bias\", \"encoder._blocks.5._bn2.running_mean\", \"encoder._blocks.5._bn2.running_var\", \"encoder._blocks.6._expand_conv.weight\", \"encoder._blocks.6._bn0.weight\", \"encoder._blocks.6._bn0.bias\", \"encoder._blocks.6._bn0.running_mean\", \"encoder._blocks.6._bn0.running_var\", \"encoder._blocks.6._depthwise_conv.weight\", \"encoder._blocks.6._bn1.weight\", \"encoder._blocks.6._bn1.bias\", \"encoder._blocks.6._bn1.running_mean\", \"encoder._blocks.6._bn1.running_var\", \"encoder._blocks.6._se_reduce.weight\", \"encoder._blocks.6._se_reduce.bias\", \"encoder._blocks.6._se_expand.weight\", \"encoder._blocks.6._se_expand.bias\", \"encoder._blocks.6._project_conv.weight\", \"encoder._blocks.6._bn2.weight\", \"encoder._blocks.6._bn2.bias\", \"encoder._blocks.6._bn2.running_mean\", \"encoder._blocks.6._bn2.running_var\", \"encoder._blocks.7._expand_conv.weight\", \"encoder._blocks.7._bn0.weight\", \"encoder._blocks.7._bn0.bias\", \"encoder._blocks.7._bn0.running_mean\", \"encoder._blocks.7._bn0.running_var\", \"encoder._blocks.7._depthwise_conv.weight\", \"encoder._blocks.7._bn1.weight\", \"encoder._blocks.7._bn1.bias\", \"encoder._blocks.7._bn1.running_mean\", \"encoder._blocks.7._bn1.running_var\", \"encoder._blocks.7._se_reduce.weight\", \"encoder._blocks.7._se_reduce.bias\", \"encoder._blocks.7._se_expand.weight\", \"encoder._blocks.7._se_expand.bias\", \"encoder._blocks.7._project_conv.weight\", \"encoder._blocks.7._bn2.weight\", \"encoder._blocks.7._bn2.bias\", \"encoder._blocks.7._bn2.running_mean\", \"encoder._blocks.7._bn2.running_var\", \"encoder._blocks.8._expand_conv.weight\", \"encoder._blocks.8._bn0.weight\", \"encoder._blocks.8._bn0.bias\", \"encoder._blocks.8._bn0.running_mean\", \"encoder._blocks.8._bn0.running_var\", \"encoder._blocks.8._depthwise_conv.weight\", \"encoder._blocks.8._bn1.weight\", \"encoder._blocks.8._bn1.bias\", \"encoder._blocks.8._bn1.running_mean\", \"encoder._blocks.8._bn1.running_var\", \"encoder._blocks.8._se_reduce.weight\", \"encoder._blocks.8._se_reduce.bias\", \"encoder._blocks.8._se_expand.weight\", \"encoder._blocks.8._se_expand.bias\", \"encoder._blocks.8._project_conv.weight\", \"encoder._blocks.8._bn2.weight\", \"encoder._blocks.8._bn2.bias\", \"encoder._blocks.8._bn2.running_mean\", \"encoder._blocks.8._bn2.running_var\", \"encoder._blocks.9._expand_conv.weight\", \"encoder._blocks.9._bn0.weight\", \"encoder._blocks.9._bn0.bias\", \"encoder._blocks.9._bn0.running_mean\", \"encoder._blocks.9._bn0.running_var\", \"encoder._blocks.9._depthwise_conv.weight\", \"encoder._blocks.9._bn1.weight\", \"encoder._blocks.9._bn1.bias\", \"encoder._blocks.9._bn1.running_mean\", \"encoder._blocks.9._bn1.running_var\", \"encoder._blocks.9._se_reduce.weight\", \"encoder._blocks.9._se_reduce.bias\", \"encoder._blocks.9._se_expand.weight\", \"encoder._blocks.9._se_expand.bias\", \"encoder._blocks.9._project_conv.weight\", \"encoder._blocks.9._bn2.weight\", \"encoder._blocks.9._bn2.bias\", \"encoder._blocks.9._bn2.running_mean\", \"encoder._blocks.9._bn2.running_var\", \"encoder._blocks.10._expand_conv.weight\", \"encoder._blocks.10._bn0.weight\", \"encoder._blocks.10._bn0.bias\", \"encoder._blocks.10._bn0.running_mean\", \"encoder._blocks.10._bn0.running_var\", \"encoder._blocks.10._depthwise_conv.weight\", \"encoder._blocks.10._bn1.weight\", \"encoder._blocks.10._bn1.bias\", \"encoder._blocks.10._bn1.running_mean\", \"encoder._blocks.10._bn1.running_var\", \"encoder._blocks.10._se_reduce.weight\", \"encoder._blocks.10._se_reduce.bias\", \"encoder._blocks.10._se_expand.weight\", \"encoder._blocks.10._se_expand.bias\", \"encoder._blocks.10._project_conv.weight\", \"encoder._blocks.10._bn2.weight\", \"encoder._blocks.10._bn2.bias\", \"encoder._blocks.10._bn2.running_mean\", \"encoder._blocks.10._bn2.running_var\", \"encoder._blocks.11._expand_conv.weight\", \"encoder._blocks.11._bn0.weight\", \"encoder._blocks.11._bn0.bias\", \"encoder._blocks.11._bn0.running_mean\", \"encoder._blocks.11._bn0.running_var\", \"encoder._blocks.11._depthwise_conv.weight\", \"encoder._blocks.11._bn1.weight\", \"encoder._blocks.11._bn1.bias\", \"encoder._blocks.11._bn1.running_mean\", \"encoder._blocks.11._bn1.running_var\", \"encoder._blocks.11._se_reduce.weight\", \"encoder._blocks.11._se_reduce.bias\", \"encoder._blocks.11._se_expand.weight\", \"encoder._blocks.11._se_expand.bias\", \"encoder._blocks.11._project_conv.weight\", \"encoder._blocks.11._bn2.weight\", \"encoder._blocks.11._bn2.bias\", \"encoder._blocks.11._bn2.running_mean\", \"encoder._blocks.11._bn2.running_var\", \"encoder._blocks.12._expand_conv.weight\", \"encoder._blocks.12._bn0.weight\", \"encoder._blocks.12._bn0.bias\", \"encoder._blocks.12._bn0.running_mean\", \"encoder._blocks.12._bn0.running_var\", \"encoder._blocks.12._depthwise_conv.weight\", \"encoder._blocks.12._bn1.weight\", \"encoder._blocks.12._bn1.bias\", \"encoder._blocks.12._bn1.running_mean\", \"encoder._blocks.12._bn1.running_var\", \"encoder._blocks.12._se_reduce.weight\", \"encoder._blocks.12._se_reduce.bias\", \"encoder._blocks.12._se_expand.weight\", \"encoder._blocks.12._se_expand.bias\", \"encoder._blocks.12._project_conv.weight\", \"encoder._blocks.12._bn2.weight\", \"encoder._blocks.12._bn2.bias\", \"encoder._blocks.12._bn2.running_mean\", \"encoder._blocks.12._bn2.running_var\", \"encoder._blocks.13._expand_conv.weight\", \"encoder._blocks.13._bn0.weight\", \"encoder._blocks.13._bn0.bias\", \"encoder._blocks.13._bn0.running_mean\", \"encoder._blocks.13._bn0.running_var\", \"encoder._blocks.13._depthwise_conv.weight\", \"encoder._blocks.13._bn1.weight\", \"encoder._blocks.13._bn1.bias\", \"encoder._blocks.13._bn1.running_mean\", \"encoder._blocks.13._bn1.running_var\", \"encoder._blocks.13._se_reduce.weight\", \"encoder._blocks.13._se_reduce.bias\", \"encoder._blocks.13._se_expand.weight\", \"encoder._blocks.13._se_expand.bias\", \"encoder._blocks.13._project_conv.weight\", \"encoder._blocks.13._bn2.weight\", \"encoder._blocks.13._bn2.bias\", \"encoder._blocks.13._bn2.running_mean\", \"encoder._blocks.13._bn2.running_var\", \"encoder._blocks.14._expand_conv.weight\", \"encoder._blocks.14._bn0.weight\", \"encoder._blocks.14._bn0.bias\", \"encoder._blocks.14._bn0.running_mean\", \"encoder._blocks.14._bn0.running_var\", \"encoder._blocks.14._depthwise_conv.weight\", \"encoder._blocks.14._bn1.weight\", \"encoder._blocks.14._bn1.bias\", \"encoder._blocks.14._bn1.running_mean\", \"encoder._blocks.14._bn1.running_var\", \"encoder._blocks.14._se_reduce.weight\", \"encoder._blocks.14._se_reduce.bias\", \"encoder._blocks.14._se_expand.weight\", \"encoder._blocks.14._se_expand.bias\", \"encoder._blocks.14._project_conv.weight\", \"encoder._blocks.14._bn2.weight\", \"encoder._blocks.14._bn2.bias\", \"encoder._blocks.14._bn2.running_mean\", \"encoder._blocks.14._bn2.running_var\", \"encoder._blocks.15._expand_conv.weight\", \"encoder._blocks.15._bn0.weight\", \"encoder._blocks.15._bn0.bias\", \"encoder._blocks.15._bn0.running_mean\", \"encoder._blocks.15._bn0.running_var\", \"encoder._blocks.15._depthwise_conv.weight\", \"encoder._blocks.15._bn1.weight\", \"encoder._blocks.15._bn1.bias\", \"encoder._blocks.15._bn1.running_mean\", \"encoder._blocks.15._bn1.running_var\", \"encoder._blocks.15._se_reduce.weight\", \"encoder._blocks.15._se_reduce.bias\", \"encoder._blocks.15._se_expand.weight\", \"encoder._blocks.15._se_expand.bias\", \"encoder._blocks.15._project_conv.weight\", \"encoder._blocks.15._bn2.weight\", \"encoder._blocks.15._bn2.bias\", \"encoder._blocks.15._bn2.running_mean\", \"encoder._blocks.15._bn2.running_var\", \"encoder._blocks.16._expand_conv.weight\", \"encoder._blocks.16._bn0.weight\", \"encoder._blocks.16._bn0.bias\", \"encoder._blocks.16._bn0.running_mean\", \"encoder._blocks.16._bn0.running_var\", \"encoder._blocks.16._depthwise_conv.weight\", \"encoder._blocks.16._bn1.weight\", \"encoder._blocks.16._bn1.bias\", \"encoder._blocks.16._bn1.running_mean\", \"encoder._blocks.16._bn1.running_var\", \"encoder._blocks.16._se_reduce.weight\", \"encoder._blocks.16._se_reduce.bias\", \"encoder._blocks.16._se_expand.weight\", \"encoder._blocks.16._se_expand.bias\", \"encoder._blocks.16._project_conv.weight\", \"encoder._blocks.16._bn2.weight\", \"encoder._blocks.16._bn2.bias\", \"encoder._blocks.16._bn2.running_mean\", \"encoder._blocks.16._bn2.running_var\", \"encoder._blocks.17._expand_conv.weight\", \"encoder._blocks.17._bn0.weight\", \"encoder._blocks.17._bn0.bias\", \"encoder._blocks.17._bn0.running_mean\", \"encoder._blocks.17._bn0.running_var\", \"encoder._blocks.17._depthwise_conv.weight\", \"encoder._blocks.17._bn1.weight\", \"encoder._blocks.17._bn1.bias\", \"encoder._blocks.17._bn1.running_mean\", \"encoder._blocks.17._bn1.running_var\", \"encoder._blocks.17._se_reduce.weight\", \"encoder._blocks.17._se_reduce.bias\", \"encoder._blocks.17._se_expand.weight\", \"encoder._blocks.17._se_expand.bias\", \"encoder._blocks.17._project_conv.weight\", \"encoder._blocks.17._bn2.weight\", \"encoder._blocks.17._bn2.bias\", \"encoder._blocks.17._bn2.running_mean\", \"encoder._blocks.17._bn2.running_var\", \"encoder._blocks.18._expand_conv.weight\", \"encoder._blocks.18._bn0.weight\", \"encoder._blocks.18._bn0.bias\", \"encoder._blocks.18._bn0.running_mean\", \"encoder._blocks.18._bn0.running_var\", \"encoder._blocks.18._depthwise_conv.weight\", \"encoder._blocks.18._bn1.weight\", \"encoder._blocks.18._bn1.bias\", \"encoder._blocks.18._bn1.running_mean\", \"encoder._blocks.18._bn1.running_var\", \"encoder._blocks.18._se_reduce.weight\", \"encoder._blocks.18._se_reduce.bias\", \"encoder._blocks.18._se_expand.weight\", \"encoder._blocks.18._se_expand.bias\", \"encoder._blocks.18._project_conv.weight\", \"encoder._blocks.18._bn2.weight\", \"encoder._blocks.18._bn2.bias\", \"encoder._blocks.18._bn2.running_mean\", \"encoder._blocks.18._bn2.running_var\", \"encoder._blocks.19._expand_conv.weight\", \"encoder._blocks.19._bn0.weight\", \"encoder._blocks.19._bn0.bias\", \"encoder._blocks.19._bn0.running_mean\", \"encoder._blocks.19._bn0.running_var\", \"encoder._blocks.19._depthwise_conv.weight\", \"encoder._blocks.19._bn1.weight\", \"encoder._blocks.19._bn1.bias\", \"encoder._blocks.19._bn1.running_mean\", \"encoder._blocks.19._bn1.running_var\", \"encoder._blocks.19._se_reduce.weight\", \"encoder._blocks.19._se_reduce.bias\", \"encoder._blocks.19._se_expand.weight\", \"encoder._blocks.19._se_expand.bias\", \"encoder._blocks.19._project_conv.weight\", \"encoder._blocks.19._bn2.weight\", \"encoder._blocks.19._bn2.bias\", \"encoder._blocks.19._bn2.running_mean\", \"encoder._blocks.19._bn2.running_var\", \"encoder._blocks.20._expand_conv.weight\", \"encoder._blocks.20._bn0.weight\", \"encoder._blocks.20._bn0.bias\", \"encoder._blocks.20._bn0.running_mean\", \"encoder._blocks.20._bn0.running_var\", \"encoder._blocks.20._depthwise_conv.weight\", \"encoder._blocks.20._bn1.weight\", \"encoder._blocks.20._bn1.bias\", \"encoder._blocks.20._bn1.running_mean\", \"encoder._blocks.20._bn1.running_var\", \"encoder._blocks.20._se_reduce.weight\", \"encoder._blocks.20._se_reduce.bias\", \"encoder._blocks.20._se_expand.weight\", \"encoder._blocks.20._se_expand.bias\", \"encoder._blocks.20._project_conv.weight\", \"encoder._blocks.20._bn2.weight\", \"encoder._blocks.20._bn2.bias\", \"encoder._blocks.20._bn2.running_mean\", \"encoder._blocks.20._bn2.running_var\", \"encoder._blocks.21._expand_conv.weight\", \"encoder._blocks.21._bn0.weight\", \"encoder._blocks.21._bn0.bias\", \"encoder._blocks.21._bn0.running_mean\", \"encoder._blocks.21._bn0.running_var\", \"encoder._blocks.21._depthwise_conv.weight\", \"encoder._blocks.21._bn1.weight\", \"encoder._blocks.21._bn1.bias\", \"encoder._blocks.21._bn1.running_mean\", \"encoder._blocks.21._bn1.running_var\", \"encoder._blocks.21._se_reduce.weight\", \"encoder._blocks.21._se_reduce.bias\", \"encoder._blocks.21._se_expand.weight\", \"encoder._blocks.21._se_expand.bias\", \"encoder._blocks.21._project_conv.weight\", \"encoder._blocks.21._bn2.weight\", \"encoder._blocks.21._bn2.bias\", \"encoder._blocks.21._bn2.running_mean\", \"encoder._blocks.21._bn2.running_var\", \"encoder._blocks.22._expand_conv.weight\", \"encoder._blocks.22._bn0.weight\", \"encoder._blocks.22._bn0.bias\", \"encoder._blocks.22._bn0.running_mean\", \"encoder._blocks.22._bn0.running_var\", \"encoder._blocks.22._depthwise_conv.weight\", \"encoder._blocks.22._bn1.weight\", \"encoder._blocks.22._bn1.bias\", \"encoder._blocks.22._bn1.running_mean\", \"encoder._blocks.22._bn1.running_var\", \"encoder._blocks.22._se_reduce.weight\", \"encoder._blocks.22._se_reduce.bias\", \"encoder._blocks.22._se_expand.weight\", \"encoder._blocks.22._se_expand.bias\", \"encoder._blocks.22._project_conv.weight\", \"encoder._blocks.22._bn2.weight\", \"encoder._blocks.22._bn2.bias\", \"encoder._blocks.22._bn2.running_mean\", \"encoder._blocks.22._bn2.running_var\", \"encoder._blocks.23._expand_conv.weight\", \"encoder._blocks.23._bn0.weight\", \"encoder._blocks.23._bn0.bias\", \"encoder._blocks.23._bn0.running_mean\", \"encoder._blocks.23._bn0.running_var\", \"encoder._blocks.23._depthwise_conv.weight\", \"encoder._blocks.23._bn1.weight\", \"encoder._blocks.23._bn1.bias\", \"encoder._blocks.23._bn1.running_mean\", \"encoder._blocks.23._bn1.running_var\", \"encoder._blocks.23._se_reduce.weight\", \"encoder._blocks.23._se_reduce.bias\", \"encoder._blocks.23._se_expand.weight\", \"encoder._blocks.23._se_expand.bias\", \"encoder._blocks.23._project_conv.weight\", \"encoder._blocks.23._bn2.weight\", \"encoder._blocks.23._bn2.bias\", \"encoder._blocks.23._bn2.running_mean\", \"encoder._blocks.23._bn2.running_var\", \"encoder._blocks.24._expand_conv.weight\", \"encoder._blocks.24._bn0.weight\", \"encoder._blocks.24._bn0.bias\", \"encoder._blocks.24._bn0.running_mean\", \"encoder._blocks.24._bn0.running_var\", \"encoder._blocks.24._depthwise_conv.weight\", \"encoder._blocks.24._bn1.weight\", \"encoder._blocks.24._bn1.bias\", \"encoder._blocks.24._bn1.running_mean\", \"encoder._blocks.24._bn1.running_var\", \"encoder._blocks.24._se_reduce.weight\", \"encoder._blocks.24._se_reduce.bias\", \"encoder._blocks.24._se_expand.weight\", \"encoder._blocks.24._se_expand.bias\", \"encoder._blocks.24._project_conv.weight\", \"encoder._blocks.24._bn2.weight\", \"encoder._blocks.24._bn2.bias\", \"encoder._blocks.24._bn2.running_mean\", \"encoder._blocks.24._bn2.running_var\", \"encoder._blocks.25._expand_conv.weight\", \"encoder._blocks.25._bn0.weight\", \"encoder._blocks.25._bn0.bias\", \"encoder._blocks.25._bn0.running_mean\", \"encoder._blocks.25._bn0.running_var\", \"encoder._blocks.25._depthwise_conv.weight\", \"encoder._blocks.25._bn1.weight\", \"encoder._blocks.25._bn1.bias\", \"encoder._blocks.25._bn1.running_mean\", \"encoder._blocks.25._bn1.running_var\", \"encoder._blocks.25._se_reduce.weight\", \"encoder._blocks.25._se_reduce.bias\", \"encoder._blocks.25._se_expand.weight\", \"encoder._blocks.25._se_expand.bias\", \"encoder._blocks.25._project_conv.weight\", \"encoder._blocks.25._bn2.weight\", \"encoder._blocks.25._bn2.bias\", \"encoder._blocks.25._bn2.running_mean\", \"encoder._blocks.25._bn2.running_var\", \"encoder._blocks.26._expand_conv.weight\", \"encoder._blocks.26._bn0.weight\", \"encoder._blocks.26._bn0.bias\", \"encoder._blocks.26._bn0.running_mean\", \"encoder._blocks.26._bn0.running_var\", \"encoder._blocks.26._depthwise_conv.weight\", \"encoder._blocks.26._bn1.weight\", \"encoder._blocks.26._bn1.bias\", \"encoder._blocks.26._bn1.running_mean\", \"encoder._blocks.26._bn1.running_var\", \"encoder._blocks.26._se_reduce.weight\", \"encoder._blocks.26._se_reduce.bias\", \"encoder._blocks.26._se_expand.weight\", \"encoder._blocks.26._se_expand.bias\", \"encoder._blocks.26._project_conv.weight\", \"encoder._blocks.26._bn2.weight\", \"encoder._blocks.26._bn2.bias\", \"encoder._blocks.26._bn2.running_mean\", \"encoder._blocks.26._bn2.running_var\", \"encoder._blocks.27._expand_conv.weight\", \"encoder._blocks.27._bn0.weight\", \"encoder._blocks.27._bn0.bias\", \"encoder._blocks.27._bn0.running_mean\", \"encoder._blocks.27._bn0.running_var\", \"encoder._blocks.27._depthwise_conv.weight\", \"encoder._blocks.27._bn1.weight\", \"encoder._blocks.27._bn1.bias\", \"encoder._blocks.27._bn1.running_mean\", \"encoder._blocks.27._bn1.running_var\", \"encoder._blocks.27._se_reduce.weight\", \"encoder._blocks.27._se_reduce.bias\", \"encoder._blocks.27._se_expand.weight\", \"encoder._blocks.27._se_expand.bias\", \"encoder._blocks.27._project_conv.weight\", \"encoder._blocks.27._bn2.weight\", \"encoder._blocks.27._bn2.bias\", \"encoder._blocks.27._bn2.running_mean\", \"encoder._blocks.27._bn2.running_var\", \"encoder._blocks.28._expand_conv.weight\", \"encoder._blocks.28._bn0.weight\", \"encoder._blocks.28._bn0.bias\", \"encoder._blocks.28._bn0.running_mean\", \"encoder._blocks.28._bn0.running_var\", \"encoder._blocks.28._depthwise_conv.weight\", \"encoder._blocks.28._bn1.weight\", \"encoder._blocks.28._bn1.bias\", \"encoder._blocks.28._bn1.running_mean\", \"encoder._blocks.28._bn1.running_var\", \"encoder._blocks.28._se_reduce.weight\", \"encoder._blocks.28._se_reduce.bias\", \"encoder._blocks.28._se_expand.weight\", \"encoder._blocks.28._se_expand.bias\", \"encoder._blocks.28._project_conv.weight\", \"encoder._blocks.28._bn2.weight\", \"encoder._blocks.28._bn2.bias\", \"encoder._blocks.28._bn2.running_mean\", \"encoder._blocks.28._bn2.running_var\", \"encoder._blocks.29._expand_conv.weight\", \"encoder._blocks.29._bn0.weight\", \"encoder._blocks.29._bn0.bias\", \"encoder._blocks.29._bn0.running_mean\", \"encoder._blocks.29._bn0.running_var\", \"encoder._blocks.29._depthwise_conv.weight\", \"encoder._blocks.29._bn1.weight\", \"encoder._blocks.29._bn1.bias\", \"encoder._blocks.29._bn1.running_mean\", \"encoder._blocks.29._bn1.running_var\", \"encoder._blocks.29._se_reduce.weight\", \"encoder._blocks.29._se_reduce.bias\", \"encoder._blocks.29._se_expand.weight\", \"encoder._blocks.29._se_expand.bias\", \"encoder._blocks.29._project_conv.weight\", \"encoder._blocks.29._bn2.weight\", \"encoder._blocks.29._bn2.bias\", \"encoder._blocks.29._bn2.running_mean\", \"encoder._blocks.29._bn2.running_var\", \"encoder._blocks.30._expand_conv.weight\", \"encoder._blocks.30._bn0.weight\", \"encoder._blocks.30._bn0.bias\", \"encoder._blocks.30._bn0.running_mean\", \"encoder._blocks.30._bn0.running_var\", \"encoder._blocks.30._depthwise_conv.weight\", \"encoder._blocks.30._bn1.weight\", \"encoder._blocks.30._bn1.bias\", \"encoder._blocks.30._bn1.running_mean\", \"encoder._blocks.30._bn1.running_var\", \"encoder._blocks.30._se_reduce.weight\", \"encoder._blocks.30._se_reduce.bias\", \"encoder._blocks.30._se_expand.weight\", \"encoder._blocks.30._se_expand.bias\", \"encoder._blocks.30._project_conv.weight\", \"encoder._blocks.30._bn2.weight\", \"encoder._blocks.30._bn2.bias\", \"encoder._blocks.30._bn2.running_mean\", \"encoder._blocks.30._bn2.running_var\", \"encoder._blocks.31._expand_conv.weight\", \"encoder._blocks.31._bn0.weight\", \"encoder._blocks.31._bn0.bias\", \"encoder._blocks.31._bn0.running_mean\", \"encoder._blocks.31._bn0.running_var\", \"encoder._blocks.31._depthwise_conv.weight\", \"encoder._blocks.31._bn1.weight\", \"encoder._blocks.31._bn1.bias\", \"encoder._blocks.31._bn1.running_mean\", \"encoder._blocks.31._bn1.running_var\", \"encoder._blocks.31._se_reduce.weight\", \"encoder._blocks.31._se_reduce.bias\", \"encoder._blocks.31._se_expand.weight\", \"encoder._blocks.31._se_expand.bias\", \"encoder._blocks.31._project_conv.weight\", \"encoder._blocks.31._bn2.weight\", \"encoder._blocks.31._bn2.bias\", \"encoder._blocks.31._bn2.running_mean\", \"encoder._blocks.31._bn2.running_var\", \"encoder._conv_head.weight\", \"encoder._bn1.weight\", \"encoder._bn1.bias\", \"encoder._bn1.running_mean\", \"encoder._bn1.running_var\". \n\tUnexpected key(s) in state_dict: \"encoder.conv1.weight\", \"encoder.bn1.weight\", \"encoder.bn1.bias\", \"encoder.bn1.running_mean\", \"encoder.bn1.running_var\", \"encoder.bn1.num_batches_tracked\", \"encoder.layer1.0.conv1.weight\", \"encoder.layer1.0.bn1.weight\", \"encoder.layer1.0.bn1.bias\", \"encoder.layer1.0.bn1.running_mean\", \"encoder.layer1.0.bn1.running_var\", \"encoder.layer1.0.bn1.num_batches_tracked\", \"encoder.layer1.0.conv2.weight\", \"encoder.layer1.0.bn2.weight\", \"encoder.layer1.0.bn2.bias\", \"encoder.layer1.0.bn2.running_mean\", \"encoder.layer1.0.bn2.running_var\", \"encoder.layer1.0.bn2.num_batches_tracked\", \"encoder.layer1.0.conv3.weight\", \"encoder.layer1.0.bn3.weight\", \"encoder.layer1.0.bn3.bias\", \"encoder.layer1.0.bn3.running_mean\", \"encoder.layer1.0.bn3.running_var\", \"encoder.layer1.0.bn3.num_batches_tracked\", \"encoder.layer1.0.downsample.0.weight\", \"encoder.layer1.0.downsample.1.weight\", \"encoder.layer1.0.downsample.1.bias\", \"encoder.layer1.0.downsample.1.running_mean\", \"encoder.layer1.0.downsample.1.running_var\", \"encoder.layer1.0.downsample.1.num_batches_tracked\", \"encoder.layer1.1.conv1.weight\", \"encoder.layer1.1.bn1.weight\", \"encoder.layer1.1.bn1.bias\", \"encoder.layer1.1.bn1.running_mean\", \"encoder.layer1.1.bn1.running_var\", \"encoder.layer1.1.bn1.num_batches_tracked\", \"encoder.layer1.1.conv2.weight\", \"encoder.layer1.1.bn2.weight\", \"encoder.layer1.1.bn2.bias\", \"encoder.layer1.1.bn2.running_mean\", \"encoder.layer1.1.bn2.running_var\", \"encoder.layer1.1.bn2.num_batches_tracked\", \"encoder.layer1.1.conv3.weight\", \"encoder.layer1.1.bn3.weight\", \"encoder.layer1.1.bn3.bias\", \"encoder.layer1.1.bn3.running_mean\", \"encoder.layer1.1.bn3.running_var\", \"encoder.layer1.1.bn3.num_batches_tracked\", \"encoder.layer1.2.conv1.weight\", \"encoder.layer1.2.bn1.weight\", \"encoder.layer1.2.bn1.bias\", \"encoder.layer1.2.bn1.running_mean\", \"encoder.layer1.2.bn1.running_var\", \"encoder.layer1.2.bn1.num_batches_tracked\", \"encoder.layer1.2.conv2.weight\", \"encoder.layer1.2.bn2.weight\", \"encoder.layer1.2.bn2.bias\", \"encoder.layer1.2.bn2.running_mean\", \"encoder.layer1.2.bn2.running_var\", \"encoder.layer1.2.bn2.num_batches_tracked\", \"encoder.layer1.2.conv3.weight\", \"encoder.layer1.2.bn3.weight\", \"encoder.layer1.2.bn3.bias\", \"encoder.layer1.2.bn3.running_mean\", \"encoder.layer1.2.bn3.running_var\", \"encoder.layer1.2.bn3.num_batches_tracked\", \"encoder.layer2.0.conv1.weight\", \"encoder.layer2.0.bn1.weight\", \"encoder.layer2.0.bn1.bias\", \"encoder.layer2.0.bn1.running_mean\", \"encoder.layer2.0.bn1.running_var\", \"encoder.layer2.0.bn1.num_batches_tracked\", \"encoder.layer2.0.conv2.weight\", \"encoder.layer2.0.bn2.weight\", \"encoder.layer2.0.bn2.bias\", \"encoder.layer2.0.bn2.running_mean\", \"encoder.layer2.0.bn2.running_var\", \"encoder.layer2.0.bn2.num_batches_tracked\", \"encoder.layer2.0.conv3.weight\", \"encoder.layer2.0.bn3.weight\", \"encoder.layer2.0.bn3.bias\", \"encoder.layer2.0.bn3.running_mean\", \"encoder.layer2.0.bn3.running_var\", \"encoder.layer2.0.bn3.num_batches_tracked\", \"encoder.layer2.0.downsample.0.weight\", \"encoder.layer2.0.downsample.1.weight\", \"encoder.layer2.0.downsample.1.bias\", \"encoder.layer2.0.downsample.1.running_mean\", \"encoder.layer2.0.downsample.1.running_var\", \"encoder.layer2.0.downsample.1.num_batches_tracked\", \"encoder.layer2.1.conv1.weight\", \"encoder.layer2.1.bn1.weight\", \"encoder.layer2.1.bn1.bias\", \"encoder.layer2.1.bn1.running_mean\", \"encoder.layer2.1.bn1.running_var\", \"encoder.layer2.1.bn1.num_batches_tracked\", \"encoder.layer2.1.conv2.weight\", \"encoder.layer2.1.bn2.weight\", \"encoder.layer2.1.bn2.bias\", \"encoder.layer2.1.bn2.running_mean\", \"encoder.layer2.1.bn2.running_var\", \"encoder.layer2.1.bn2.num_batches_tracked\", \"encoder.layer2.1.conv3.weight\", \"encoder.layer2.1.bn3.weight\", \"encoder.layer2.1.bn3.bias\", \"encoder.layer2.1.bn3.running_mean\", \"encoder.layer2.1.bn3.running_var\", \"encoder.layer2.1.bn3.num_batches_tracked\", \"encoder.layer2.2.conv1.weight\", \"encoder.layer2.2.bn1.weight\", \"encoder.layer2.2.bn1.bias\", \"encoder.layer2.2.bn1.running_mean\", \"encoder.layer2.2.bn1.running_var\", \"encoder.layer2.2.bn1.num_batches_tracked\", \"encoder.layer2.2.conv2.weight\", \"encoder.layer2.2.bn2.weight\", \"encoder.layer2.2.bn2.bias\", \"encoder.layer2.2.bn2.running_mean\", \"encoder.layer2.2.bn2.running_var\", \"encoder.layer2.2.bn2.num_batches_tracked\", \"encoder.layer2.2.conv3.weight\", \"encoder.layer2.2.bn3.weight\", \"encoder.layer2.2.bn3.bias\", \"encoder.layer2.2.bn3.running_mean\", \"encoder.layer2.2.bn3.running_var\", \"encoder.layer2.2.bn3.num_batches_tracked\", \"encoder.layer2.3.conv1.weight\", \"encoder.layer2.3.bn1.weight\", \"encoder.layer2.3.bn1.bias\", \"encoder.layer2.3.bn1.running_mean\", \"encoder.layer2.3.bn1.running_var\", \"encoder.layer2.3.bn1.num_batches_tracked\", \"encoder.layer2.3.conv2.weight\", \"encoder.layer2.3.bn2.weight\", \"encoder.layer2.3.bn2.bias\", \"encoder.layer2.3.bn2.running_mean\", \"encoder.layer2.3.bn2.running_var\", \"encoder.layer2.3.bn2.num_batches_tracked\", \"encoder.layer2.3.conv3.weight\", \"encoder.layer2.3.bn3.weight\", \"encoder.layer2.3.bn3.bias\", \"encoder.layer2.3.bn3.running_mean\", \"encoder.layer2.3.bn3.running_var\", \"encoder.layer2.3.bn3.num_batches_tracked\", \"encoder.layer3.0.conv1.weight\", \"encoder.layer3.0.bn1.weight\", \"encoder.layer3.0.bn1.bias\", \"encoder.layer3.0.bn1.running_mean\", \"encoder.layer3.0.bn1.running_var\", \"encoder.layer3.0.bn1.num_batches_tracked\", \"encoder.layer3.0.conv2.weight\", \"encoder.layer3.0.bn2.weight\", \"encoder.layer3.0.bn2.bias\", \"encoder.layer3.0.bn2.running_mean\", \"encoder.layer3.0.bn2.running_var\", \"encoder.layer3.0.bn2.num_batches_tracked\", \"encoder.layer3.0.conv3.weight\", \"encoder.layer3.0.bn3.weight\", \"encoder.layer3.0.bn3.bias\", \"encoder.layer3.0.bn3.running_mean\", \"encoder.layer3.0.bn3.running_var\", \"encoder.layer3.0.bn3.num_batches_tracked\", \"encoder.layer3.0.downsample.0.weight\", \"encoder.layer3.0.downsample.1.weight\", \"encoder.layer3.0.downsample.1.bias\", \"encoder.layer3.0.downsample.1.running_mean\", \"encoder.layer3.0.downsample.1.running_var\", \"encoder.layer3.0.downsample.1.num_batches_tracked\", \"encoder.layer3.1.conv1.weight\", \"encoder.layer3.1.bn1.weight\", \"encoder.layer3.1.bn1.bias\", \"encoder.layer3.1.bn1.running_mean\", \"encoder.layer3.1.bn1.running_var\", \"encoder.layer3.1.bn1.num_batches_tracked\", \"encoder.layer3.1.conv2.weight\", \"encoder.layer3.1.bn2.weight\", \"encoder.layer3.1.bn2.bias\", \"encoder.layer3.1.bn2.running_mean\", \"encoder.layer3.1.bn2.running_var\", \"encoder.layer3.1.bn2.num_batches_tracked\", \"encoder.layer3.1.conv3.weight\", \"encoder.layer3.1.bn3.weight\", \"encoder.layer3.1.bn3.bias\", \"encoder.layer3.1.bn3.running_mean\", \"encoder.layer3.1.bn3.running_var\", \"encoder.layer3.1.bn3.num_batches_tracked\", \"encoder.layer3.2.conv1.weight\", \"encoder.layer3.2.bn1.weight\", \"encoder.layer3.2.bn1.bias\", \"encoder.layer3.2.bn1.running_mean\", \"encoder.layer3.2.bn1.running_var\", \"encoder.layer3.2.bn1.num_batches_tracked\", \"encoder.layer3.2.conv2.weight\", \"encoder.layer3.2.bn2.weight\", \"encoder.layer3.2.bn2.bias\", \"encoder.layer3.2.bn2.running_mean\", \"encoder.layer3.2.bn2.running_var\", \"encoder.layer3.2.bn2.num_batches_tracked\", \"encoder.layer3.2.conv3.weight\", \"encoder.layer3.2.bn3.weight\", \"encoder.layer3.2.bn3.bias\", \"encoder.layer3.2.bn3.running_mean\", \"encoder.layer3.2.bn3.running_var\", \"encoder.layer3.2.bn3.num_batches_tracked\", \"encoder.layer3.3.conv1.weight\", \"encoder.layer3.3.bn1.weight\", \"encoder.layer3.3.bn1.bias\", \"encoder.layer3.3.bn1.running_mean\", \"encoder.layer3.3.bn1.running_var\", \"encoder.layer3.3.bn1.num_batches_tracked\", \"encoder.layer3.3.conv2.weight\", \"encoder.layer3.3.bn2.weight\", \"encoder.layer3.3.bn2.bias\", \"encoder.layer3.3.bn2.running_mean\", \"encoder.layer3.3.bn2.running_var\", \"encoder.layer3.3.bn2.num_batches_tracked\", \"encoder.layer3.3.conv3.weight\", \"encoder.layer3.3.bn3.weight\", \"encoder.layer3.3.bn3.bias\", \"encoder.layer3.3.bn3.running_mean\", \"encoder.layer3.3.bn3.running_var\", \"encoder.layer3.3.bn3.num_batches_tracked\", \"encoder.layer3.4.conv1.weight\", \"encoder.layer3.4.bn1.weight\", \"encoder.layer3.4.bn1.bias\", \"encoder.layer3.4.bn1.running_mean\", \"encoder.layer3.4.bn1.running_var\", \"encoder.layer3.4.bn1.num_batches_tracked\", \"encoder.layer3.4.conv2.weight\", \"encoder.layer3.4.bn2.weight\", \"encoder.layer3.4.bn2.bias\", \"encoder.layer3.4.bn2.running_mean\", \"encoder.layer3.4.bn2.running_var\", \"encoder.layer3.4.bn2.num_batches_tracked\", \"encoder.layer3.4.conv3.weight\", \"encoder.layer3.4.bn3.weight\", \"encoder.layer3.4.bn3.bias\", \"encoder.layer3.4.bn3.running_mean\", \"encoder.layer3.4.bn3.running_var\", \"encoder.layer3.4.bn3.num_batches_tracked\", \"encoder.layer3.5.conv1.weight\", \"encoder.layer3.5.bn1.weight\", \"encoder.layer3.5.bn1.bias\", \"encoder.layer3.5.bn1.running_mean\", \"encoder.layer3.5.bn1.running_var\", \"encoder.layer3.5.bn1.num_batches_tracked\", \"encoder.layer3.5.conv2.weight\", \"encoder.layer3.5.bn2.weight\", \"encoder.layer3.5.bn2.bias\", \"encoder.layer3.5.bn2.running_mean\", \"encoder.layer3.5.bn2.running_var\", \"encoder.layer3.5.bn2.num_batches_tracked\", \"encoder.layer3.5.conv3.weight\", \"encoder.layer3.5.bn3.weight\", \"encoder.layer3.5.bn3.bias\", \"encoder.layer3.5.bn3.running_mean\", \"encoder.layer3.5.bn3.running_var\", \"encoder.layer3.5.bn3.num_batches_tracked\", \"encoder.layer4.0.conv1.weight\", \"encoder.layer4.0.bn1.weight\", \"encoder.layer4.0.bn1.bias\", \"encoder.layer4.0.bn1.running_mean\", \"encoder.layer4.0.bn1.running_var\", \"encoder.layer4.0.bn1.num_batches_tracked\", \"encoder.layer4.0.conv2.weight\", \"encoder.layer4.0.bn2.weight\", \"encoder.layer4.0.bn2.bias\", \"encoder.layer4.0.bn2.running_mean\", \"encoder.layer4.0.bn2.running_var\", \"encoder.layer4.0.bn2.num_batches_tracked\", \"encoder.layer4.0.conv3.weight\", \"encoder.layer4.0.bn3.weight\", \"encoder.layer4.0.bn3.bias\", \"encoder.layer4.0.bn3.running_mean\", \"encoder.layer4.0.bn3.running_var\", \"encoder.layer4.0.bn3.num_batches_tracked\", \"encoder.layer4.0.downsample.0.weight\", \"encoder.layer4.0.downsample.1.weight\", \"encoder.layer4.0.downsample.1.bias\", \"encoder.layer4.0.downsample.1.running_mean\", \"encoder.layer4.0.downsample.1.running_var\", \"encoder.layer4.0.downsample.1.num_batches_tracked\", \"encoder.layer4.1.conv1.weight\", \"encoder.layer4.1.bn1.weight\", \"encoder.layer4.1.bn1.bias\", \"encoder.layer4.1.bn1.running_mean\", \"encoder.layer4.1.bn1.running_var\", \"encoder.layer4.1.bn1.num_batches_tracked\", \"encoder.layer4.1.conv2.weight\", \"encoder.layer4.1.bn2.weight\", \"encoder.layer4.1.bn2.bias\", \"encoder.layer4.1.bn2.running_mean\", \"encoder.layer4.1.bn2.running_var\", \"encoder.layer4.1.bn2.num_batches_tracked\", \"encoder.layer4.1.conv3.weight\", \"encoder.layer4.1.bn3.weight\", \"encoder.layer4.1.bn3.bias\", \"encoder.layer4.1.bn3.running_mean\", \"encoder.layer4.1.bn3.running_var\", \"encoder.layer4.1.bn3.num_batches_tracked\", \"encoder.layer4.2.conv1.weight\", \"encoder.layer4.2.bn1.weight\", \"encoder.layer4.2.bn1.bias\", \"encoder.layer4.2.bn1.running_mean\", \"encoder.layer4.2.bn1.running_var\", \"encoder.layer4.2.bn1.num_batches_tracked\", \"encoder.layer4.2.conv2.weight\", \"encoder.layer4.2.bn2.weight\", \"encoder.layer4.2.bn2.bias\", \"encoder.layer4.2.bn2.running_mean\", \"encoder.layer4.2.bn2.running_var\", \"encoder.layer4.2.bn2.num_batches_tracked\", \"encoder.layer4.2.conv3.weight\", \"encoder.layer4.2.bn3.weight\", \"encoder.layer4.2.bn3.bias\", \"encoder.layer4.2.bn3.running_mean\", \"encoder.layer4.2.bn3.running_var\", \"encoder.layer4.2.bn3.num_batches_tracked\". \n\tsize mismatch for decoder.blocks.0.conv1.0.weight: copying a param with shape torch.Size([256, 3072, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 608, 3, 3]).\n\tsize mismatch for decoder.blocks.1.conv1.0.weight: copying a param with shape torch.Size([128, 768, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 312, 3, 3]).\n\tsize mismatch for decoder.blocks.2.conv1.0.weight: copying a param with shape torch.Size([64, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 160, 3, 3]).\n\tsize mismatch for decoder.blocks.3.conv1.0.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 112, 3, 3]).",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/Users/giuliamonopoli/Desktop/DeepValve Summer Internship/seg.pth\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[39m# if os.path.exists('../data/models/'):\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(model_path))\n\u001b[1;32m     10\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     14\u001b[0m \u001b[39m# # load best saved model checkpoint from previous commit (if present)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# # elif os.path.exists('../input//unet-with-pretrained-resnet50-encoder-pytorch/best_model.pth'):\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m# #     best_model = torch.load('../input//unet-with-pretrained-resnet50-encoder-pytorch/best_model.pth', map_location=DEVICE)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39m# if not os.path.exists(sample_preds_folder):\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39m#     os.makedirs(sample_preds_folder)\u001b[39;00m\n",
                        "File \u001b[0;32m~/opt/anaconda3/envs/deepvalve/lib/python3.11/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
                        "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Unet:\n\tMissing key(s) in state_dict: \"encoder._conv_stem.weight\", \"encoder._bn0.weight\", \"encoder._bn0.bias\", \"encoder._bn0.running_mean\", \"encoder._bn0.running_var\", \"encoder._blocks.0._depthwise_conv.weight\", \"encoder._blocks.0._bn1.weight\", \"encoder._blocks.0._bn1.bias\", \"encoder._blocks.0._bn1.running_mean\", \"encoder._blocks.0._bn1.running_var\", \"encoder._blocks.0._se_reduce.weight\", \"encoder._blocks.0._se_reduce.bias\", \"encoder._blocks.0._se_expand.weight\", \"encoder._blocks.0._se_expand.bias\", \"encoder._blocks.0._project_conv.weight\", \"encoder._blocks.0._bn2.weight\", \"encoder._blocks.0._bn2.bias\", \"encoder._blocks.0._bn2.running_mean\", \"encoder._blocks.0._bn2.running_var\", \"encoder._blocks.1._depthwise_conv.weight\", \"encoder._blocks.1._bn1.weight\", \"encoder._blocks.1._bn1.bias\", \"encoder._blocks.1._bn1.running_mean\", \"encoder._blocks.1._bn1.running_var\", \"encoder._blocks.1._se_reduce.weight\", \"encoder._blocks.1._se_reduce.bias\", \"encoder._blocks.1._se_expand.weight\", \"encoder._blocks.1._se_expand.bias\", \"encoder._blocks.1._project_conv.weight\", \"encoder._blocks.1._bn2.weight\", \"encoder._blocks.1._bn2.bias\", \"encoder._blocks.1._bn2.running_mean\", \"encoder._blocks.1._bn2.running_var\", \"encoder._blocks.2._expand_conv.weight\", \"encoder._blocks.2._bn0.weight\", \"encoder._blocks.2._bn0.bias\", \"encoder._blocks.2._bn0.running_mean\", \"encoder._blocks.2._bn0.running_var\", \"encoder._blocks.2._depthwise_conv.weight\", \"encoder._blocks.2._bn1.weight\", \"encoder._blocks.2._bn1.bias\", \"encoder._blocks.2._bn1.running_mean\", \"encoder._blocks.2._bn1.running_var\", \"encoder._blocks.2._se_reduce.weight\", \"encoder._blocks.2._se_reduce.bias\", \"encoder._blocks.2._se_expand.weight\", \"encoder._blocks.2._se_expand.bias\", \"encoder._blocks.2._project_conv.weight\", \"encoder._blocks.2._bn2.weight\", \"encoder._blocks.2._bn2.bias\", \"encoder._blocks.2._bn2.running_mean\", \"encoder._blocks.2._bn2.running_var\", \"encoder._blocks.3._expand_conv.weight\", \"encoder._blocks.3._bn0.weight\", \"encoder._blocks.3._bn0.bias\", \"encoder._blocks.3._bn0.running_mean\", \"encoder._blocks.3._bn0.running_var\", \"encoder._blocks.3._depthwise_conv.weight\", \"encoder._blocks.3._bn1.weight\", \"encoder._blocks.3._bn1.bias\", \"encoder._blocks.3._bn1.running_mean\", \"encoder._blocks.3._bn1.running_var\", \"encoder._blocks.3._se_reduce.weight\", \"encoder._blocks.3._se_reduce.bias\", \"encoder._blocks.3._se_expand.weight\", \"encoder._blocks.3._se_expand.bias\", \"encoder._blocks.3._project_conv.weight\", \"encoder._blocks.3._bn2.weight\", \"encoder._blocks.3._bn2.bias\", \"encoder._blocks.3._bn2.running_mean\", \"encoder._blocks.3._bn2.running_var\", \"encoder._blocks.4._expand_conv.weight\", \"encoder._blocks.4._bn0.weight\", \"encoder._blocks.4._bn0.bias\", \"encoder._blocks.4._bn0.running_mean\", \"encoder._blocks.4._bn0.running_var\", \"encoder._blocks.4._depthwise_conv.weight\", \"encoder._blocks.4._bn1.weight\", \"encoder._blocks.4._bn1.bias\", \"encoder._blocks.4._bn1.running_mean\", \"encoder._blocks.4._bn1.running_var\", \"encoder._blocks.4._se_reduce.weight\", \"encoder._blocks.4._se_reduce.bias\", \"encoder._blocks.4._se_expand.weight\", \"encoder._blocks.4._se_expand.bias\", \"encoder._blocks.4._project_conv.weight\", \"encoder._blocks.4._bn2.weight\", \"encoder._blocks.4._bn2.bias\", \"encoder._blocks.4._bn2.running_mean\", \"encoder._blocks.4._bn2.running_var\", \"encoder._blocks.5._expand_conv.weight\", \"encoder._blocks.5._bn0.weight\", \"encoder._blocks.5._bn0.bias\", \"encoder._blocks.5._bn0.running_mean\", \"encoder._blocks.5._bn0.running_var\", \"encoder._blocks.5._depthwise_conv.weight\", \"encoder._blocks.5._bn1.weight\", \"encoder._blocks.5._bn1.bias\", \"encoder._blocks.5._bn1.running_mean\", \"encoder._blocks.5._bn1.running_var\", \"encoder._blocks.5._se_reduce.weight\", \"encoder._blocks.5._se_reduce.bias\", \"encoder._blocks.5._se_expand.weight\", \"encoder._blocks.5._se_expand.bias\", \"encoder._blocks.5._project_conv.weight\", \"encoder._blocks.5._bn2.weight\", \"encoder._blocks.5._bn2.bias\", \"encoder._blocks.5._bn2.running_mean\", \"encoder._blocks.5._bn2.running_var\", \"encoder._blocks.6._expand_conv.weight\", \"encoder._blocks.6._bn0.weight\", \"encoder._blocks.6._bn0.bias\", \"encoder._blocks.6._bn0.running_mean\", \"encoder._blocks.6._bn0.running_var\", \"encoder._blocks.6._depthwise_conv.weight\", \"encoder._blocks.6._bn1.weight\", \"encoder._blocks.6._bn1.bias\", \"encoder._blocks.6._bn1.running_mean\", \"encoder._blocks.6._bn1.running_var\", \"encoder._blocks.6._se_reduce.weight\", \"encoder._blocks.6._se_reduce.bias\", \"encoder._blocks.6._se_expand.weight\", \"encoder._blocks.6._se_expand.bias\", \"encoder._blocks.6._project_conv.weight\", \"encoder._blocks.6._bn2.weight\", \"encoder._blocks.6._bn2.bias\", \"encoder._blocks.6._bn2.running_mean\", \"encoder._blocks.6._bn2.running_var\", \"encoder._blocks.7._expand_conv.weight\", \"encoder._blocks.7._bn0.weight\", \"encoder._blocks.7._bn0.bias\", \"encoder._blocks.7._bn0.running_mean\", \"encoder._blocks.7._bn0.running_var\", \"encoder._blocks.7._depthwise_conv.weight\", \"encoder._blocks.7._bn1.weight\", \"encoder._blocks.7._bn1.bias\", \"encoder._blocks.7._bn1.running_mean\", \"encoder._blocks.7._bn1.running_var\", \"encoder._blocks.7._se_reduce.weight\", \"encoder._blocks.7._se_reduce.bias\", \"encoder._blocks.7._se_expand.weight\", \"encoder._blocks.7._se_expand.bias\", \"encoder._blocks.7._project_conv.weight\", \"encoder._blocks.7._bn2.weight\", \"encoder._blocks.7._bn2.bias\", \"encoder._blocks.7._bn2.running_mean\", \"encoder._blocks.7._bn2.running_var\", \"encoder._blocks.8._expand_conv.weight\", \"encoder._blocks.8._bn0.weight\", \"encoder._blocks.8._bn0.bias\", \"encoder._blocks.8._bn0.running_mean\", \"encoder._blocks.8._bn0.running_var\", \"encoder._blocks.8._depthwise_conv.weight\", \"encoder._blocks.8._bn1.weight\", \"encoder._blocks.8._bn1.bias\", \"encoder._blocks.8._bn1.running_mean\", \"encoder._blocks.8._bn1.running_var\", \"encoder._blocks.8._se_reduce.weight\", \"encoder._blocks.8._se_reduce.bias\", \"encoder._blocks.8._se_expand.weight\", \"encoder._blocks.8._se_expand.bias\", \"encoder._blocks.8._project_conv.weight\", \"encoder._blocks.8._bn2.weight\", \"encoder._blocks.8._bn2.bias\", \"encoder._blocks.8._bn2.running_mean\", \"encoder._blocks.8._bn2.running_var\", \"encoder._blocks.9._expand_conv.weight\", \"encoder._blocks.9._bn0.weight\", \"encoder._blocks.9._bn0.bias\", \"encoder._blocks.9._bn0.running_mean\", \"encoder._blocks.9._bn0.running_var\", \"encoder._blocks.9._depthwise_conv.weight\", \"encoder._blocks.9._bn1.weight\", \"encoder._blocks.9._bn1.bias\", \"encoder._blocks.9._bn1.running_mean\", \"encoder._blocks.9._bn1.running_var\", \"encoder._blocks.9._se_reduce.weight\", \"encoder._blocks.9._se_reduce.bias\", \"encoder._blocks.9._se_expand.weight\", \"encoder._blocks.9._se_expand.bias\", \"encoder._blocks.9._project_conv.weight\", \"encoder._blocks.9._bn2.weight\", \"encoder._blocks.9._bn2.bias\", \"encoder._blocks.9._bn2.running_mean\", \"encoder._blocks.9._bn2.running_var\", \"encoder._blocks.10._expand_conv.weight\", \"encoder._blocks.10._bn0.weight\", \"encoder._blocks.10._bn0.bias\", \"encoder._blocks.10._bn0.running_mean\", \"encoder._blocks.10._bn0.running_var\", \"encoder._blocks.10._depthwise_conv.weight\", \"encoder._blocks.10._bn1.weight\", \"encoder._blocks.10._bn1.bias\", \"encoder._blocks.10._bn1.running_mean\", \"encoder._blocks.10._bn1.running_var\", \"encoder._blocks.10._se_reduce.weight\", \"encoder._blocks.10._se_reduce.bias\", \"encoder._blocks.10._se_expand.weight\", \"encoder._blocks.10._se_expand.bias\", \"encoder._blocks.10._project_conv.weight\", \"encoder._blocks.10._bn2.weight\", \"encoder._blocks.10._bn2.bias\", \"encoder._blocks.10._bn2.running_mean\", \"encoder._blocks.10._bn2.running_var\", \"encoder._blocks.11._expand_conv.weight\", \"encoder._blocks.11._bn0.weight\", \"encoder._blocks.11._bn0.bias\", \"encoder._blocks.11._bn0.running_mean\", \"encoder._blocks.11._bn0.running_var\", \"encoder._blocks.11._depthwise_conv.weight\", \"encoder._blocks.11._bn1.weight\", \"encoder._blocks.11._bn1.bias\", \"encoder._blocks.11._bn1.running_mean\", \"encoder._blocks.11._bn1.running_var\", \"encoder._blocks.11._se_reduce.weight\", \"encoder._blocks.11._se_reduce.bias\", \"encoder._blocks.11._se_expand.weight\", \"encoder._blocks.11._se_expand.bias\", \"encoder._blocks.11._project_conv.weight\", \"encoder._blocks.11._bn2.weight\", \"encoder._blocks.11._bn2.bias\", \"encoder._blocks.11._bn2.running_mean\", \"encoder._blocks.11._bn2.running_var\", \"encoder._blocks.12._expand_conv.weight\", \"encoder._blocks.12._bn0.weight\", \"encoder._blocks.12._bn0.bias\", \"encoder._blocks.12._bn0.running_mean\", \"encoder._blocks.12._bn0.running_var\", \"encoder._blocks.12._depthwise_conv.weight\", \"encoder._blocks.12._bn1.weight\", \"encoder._blocks.12._bn1.bias\", \"encoder._blocks.12._bn1.running_mean\", \"encoder._blocks.12._bn1.running_var\", \"encoder._blocks.12._se_reduce.weight\", \"encoder._blocks.12._se_reduce.bias\", \"encoder._blocks.12._se_expand.weight\", \"encoder._blocks.12._se_expand.bias\", \"encoder._blocks.12._project_conv.weight\", \"encoder._blocks.12._bn2.weight\", \"encoder._blocks.12._bn2.bias\", \"encoder._blocks.12._bn2.running_mean\", \"encoder._blocks.12._bn2.running_var\", \"encoder._blocks.13._expand_conv.weight\", \"encoder._blocks.13._bn0.weight\", \"encoder._blocks.13._bn0.bias\", \"encoder._blocks.13._bn0.running_mean\", \"encoder._blocks.13._bn0.running_var\", \"encoder._blocks.13._depthwise_conv.weight\", \"encoder._blocks.13._bn1.weight\", \"encoder._blocks.13._bn1.bias\", \"encoder._blocks.13._bn1.running_mean\", \"encoder._blocks.13._bn1.running_var\", \"encoder._blocks.13._se_reduce.weight\", \"encoder._blocks.13._se_reduce.bias\", \"encoder._blocks.13._se_expand.weight\", \"encoder._blocks.13._se_expand.bias\", \"encoder._blocks.13._project_conv.weight\", \"encoder._blocks.13._bn2.weight\", \"encoder._blocks.13._bn2.bias\", \"encoder._blocks.13._bn2.running_mean\", \"encoder._blocks.13._bn2.running_var\", \"encoder._blocks.14._expand_conv.weight\", \"encoder._blocks.14._bn0.weight\", \"encoder._blocks.14._bn0.bias\", \"encoder._blocks.14._bn0.running_mean\", \"encoder._blocks.14._bn0.running_var\", \"encoder._blocks.14._depthwise_conv.weight\", \"encoder._blocks.14._bn1.weight\", \"encoder._blocks.14._bn1.bias\", \"encoder._blocks.14._bn1.running_mean\", \"encoder._blocks.14._bn1.running_var\", \"encoder._blocks.14._se_reduce.weight\", \"encoder._blocks.14._se_reduce.bias\", \"encoder._blocks.14._se_expand.weight\", \"encoder._blocks.14._se_expand.bias\", \"encoder._blocks.14._project_conv.weight\", \"encoder._blocks.14._bn2.weight\", \"encoder._blocks.14._bn2.bias\", \"encoder._blocks.14._bn2.running_mean\", \"encoder._blocks.14._bn2.running_var\", \"encoder._blocks.15._expand_conv.weight\", \"encoder._blocks.15._bn0.weight\", \"encoder._blocks.15._bn0.bias\", \"encoder._blocks.15._bn0.running_mean\", \"encoder._blocks.15._bn0.running_var\", \"encoder._blocks.15._depthwise_conv.weight\", \"encoder._blocks.15._bn1.weight\", \"encoder._blocks.15._bn1.bias\", \"encoder._blocks.15._bn1.running_mean\", \"encoder._blocks.15._bn1.running_var\", \"encoder._blocks.15._se_reduce.weight\", \"encoder._blocks.15._se_reduce.bias\", \"encoder._blocks.15._se_expand.weight\", \"encoder._blocks.15._se_expand.bias\", \"encoder._blocks.15._project_conv.weight\", \"encoder._blocks.15._bn2.weight\", \"encoder._blocks.15._bn2.bias\", \"encoder._blocks.15._bn2.running_mean\", \"encoder._blocks.15._bn2.running_var\", \"encoder._blocks.16._expand_conv.weight\", \"encoder._blocks.16._bn0.weight\", \"encoder._blocks.16._bn0.bias\", \"encoder._blocks.16._bn0.running_mean\", \"encoder._blocks.16._bn0.running_var\", \"encoder._blocks.16._depthwise_conv.weight\", \"encoder._blocks.16._bn1.weight\", \"encoder._blocks.16._bn1.bias\", \"encoder._blocks.16._bn1.running_mean\", \"encoder._blocks.16._bn1.running_var\", \"encoder._blocks.16._se_reduce.weight\", \"encoder._blocks.16._se_reduce.bias\", \"encoder._blocks.16._se_expand.weight\", \"encoder._blocks.16._se_expand.bias\", \"encoder._blocks.16._project_conv.weight\", \"encoder._blocks.16._bn2.weight\", \"encoder._blocks.16._bn2.bias\", \"encoder._blocks.16._bn2.running_mean\", \"encoder._blocks.16._bn2.running_var\", \"encoder._blocks.17._expand_conv.weight\", \"encoder._blocks.17._bn0.weight\", \"encoder._blocks.17._bn0.bias\", \"encoder._blocks.17._bn0.running_mean\", \"encoder._blocks.17._bn0.running_var\", \"encoder._blocks.17._depthwise_conv.weight\", \"encoder._blocks.17._bn1.weight\", \"encoder._blocks.17._bn1.bias\", \"encoder._blocks.17._bn1.running_mean\", \"encoder._blocks.17._bn1.running_var\", \"encoder._blocks.17._se_reduce.weight\", \"encoder._blocks.17._se_reduce.bias\", \"encoder._blocks.17._se_expand.weight\", \"encoder._blocks.17._se_expand.bias\", \"encoder._blocks.17._project_conv.weight\", \"encoder._blocks.17._bn2.weight\", \"encoder._blocks.17._bn2.bias\", \"encoder._blocks.17._bn2.running_mean\", \"encoder._blocks.17._bn2.running_var\", \"encoder._blocks.18._expand_conv.weight\", \"encoder._blocks.18._bn0.weight\", \"encoder._blocks.18._bn0.bias\", \"encoder._blocks.18._bn0.running_mean\", \"encoder._blocks.18._bn0.running_var\", \"encoder._blocks.18._depthwise_conv.weight\", \"encoder._blocks.18._bn1.weight\", \"encoder._blocks.18._bn1.bias\", \"encoder._blocks.18._bn1.running_mean\", \"encoder._blocks.18._bn1.running_var\", \"encoder._blocks.18._se_reduce.weight\", \"encoder._blocks.18._se_reduce.bias\", \"encoder._blocks.18._se_expand.weight\", \"encoder._blocks.18._se_expand.bias\", \"encoder._blocks.18._project_conv.weight\", \"encoder._blocks.18._bn2.weight\", \"encoder._blocks.18._bn2.bias\", \"encoder._blocks.18._bn2.running_mean\", \"encoder._blocks.18._bn2.running_var\", \"encoder._blocks.19._expand_conv.weight\", \"encoder._blocks.19._bn0.weight\", \"encoder._blocks.19._bn0.bias\", \"encoder._blocks.19._bn0.running_mean\", \"encoder._blocks.19._bn0.running_var\", \"encoder._blocks.19._depthwise_conv.weight\", \"encoder._blocks.19._bn1.weight\", \"encoder._blocks.19._bn1.bias\", \"encoder._blocks.19._bn1.running_mean\", \"encoder._blocks.19._bn1.running_var\", \"encoder._blocks.19._se_reduce.weight\", \"encoder._blocks.19._se_reduce.bias\", \"encoder._blocks.19._se_expand.weight\", \"encoder._blocks.19._se_expand.bias\", \"encoder._blocks.19._project_conv.weight\", \"encoder._blocks.19._bn2.weight\", \"encoder._blocks.19._bn2.bias\", \"encoder._blocks.19._bn2.running_mean\", \"encoder._blocks.19._bn2.running_var\", \"encoder._blocks.20._expand_conv.weight\", \"encoder._blocks.20._bn0.weight\", \"encoder._blocks.20._bn0.bias\", \"encoder._blocks.20._bn0.running_mean\", \"encoder._blocks.20._bn0.running_var\", \"encoder._blocks.20._depthwise_conv.weight\", \"encoder._blocks.20._bn1.weight\", \"encoder._blocks.20._bn1.bias\", \"encoder._blocks.20._bn1.running_mean\", \"encoder._blocks.20._bn1.running_var\", \"encoder._blocks.20._se_reduce.weight\", \"encoder._blocks.20._se_reduce.bias\", \"encoder._blocks.20._se_expand.weight\", \"encoder._blocks.20._se_expand.bias\", \"encoder._blocks.20._project_conv.weight\", \"encoder._blocks.20._bn2.weight\", \"encoder._blocks.20._bn2.bias\", \"encoder._blocks.20._bn2.running_mean\", \"encoder._blocks.20._bn2.running_var\", \"encoder._blocks.21._expand_conv.weight\", \"encoder._blocks.21._bn0.weight\", \"encoder._blocks.21._bn0.bias\", \"encoder._blocks.21._bn0.running_mean\", \"encoder._blocks.21._bn0.running_var\", \"encoder._blocks.21._depthwise_conv.weight\", \"encoder._blocks.21._bn1.weight\", \"encoder._blocks.21._bn1.bias\", \"encoder._blocks.21._bn1.running_mean\", \"encoder._blocks.21._bn1.running_var\", \"encoder._blocks.21._se_reduce.weight\", \"encoder._blocks.21._se_reduce.bias\", \"encoder._blocks.21._se_expand.weight\", \"encoder._blocks.21._se_expand.bias\", \"encoder._blocks.21._project_conv.weight\", \"encoder._blocks.21._bn2.weight\", \"encoder._blocks.21._bn2.bias\", \"encoder._blocks.21._bn2.running_mean\", \"encoder._blocks.21._bn2.running_var\", \"encoder._blocks.22._expand_conv.weight\", \"encoder._blocks.22._bn0.weight\", \"encoder._blocks.22._bn0.bias\", \"encoder._blocks.22._bn0.running_mean\", \"encoder._blocks.22._bn0.running_var\", \"encoder._blocks.22._depthwise_conv.weight\", \"encoder._blocks.22._bn1.weight\", \"encoder._blocks.22._bn1.bias\", \"encoder._blocks.22._bn1.running_mean\", \"encoder._blocks.22._bn1.running_var\", \"encoder._blocks.22._se_reduce.weight\", \"encoder._blocks.22._se_reduce.bias\", \"encoder._blocks.22._se_expand.weight\", \"encoder._blocks.22._se_expand.bias\", \"encoder._blocks.22._project_conv.weight\", \"encoder._blocks.22._bn2.weight\", \"encoder._blocks.22._bn2.bias\", \"encoder._blocks.22._bn2.running_mean\", \"encoder._blocks.22._bn2.running_var\", \"encoder._blocks.23._expand_conv.weight\", \"encoder._blocks.23._bn0.weight\", \"encoder._blocks.23._bn0.bias\", \"encoder._blocks.23._bn0.running_mean\", \"encoder._blocks.23._bn0.running_var\", \"encoder._blocks.23._depthwise_conv.weight\", \"encoder._blocks.23._bn1.weight\", \"encoder._blocks.23._bn1.bias\", \"encoder._blocks.23._bn1.running_mean\", \"encoder._blocks.23._bn1.running_var\", \"encoder._blocks.23._se_reduce.weight\", \"encoder._blocks.23._se_reduce.bias\", \"encoder._blocks.23._se_expand.weight\", \"encoder._blocks.23._se_expand.bias\", \"encoder._blocks.23._project_conv.weight\", \"encoder._blocks.23._bn2.weight\", \"encoder._blocks.23._bn2.bias\", \"encoder._blocks.23._bn2.running_mean\", \"encoder._blocks.23._bn2.running_var\", \"encoder._blocks.24._expand_conv.weight\", \"encoder._blocks.24._bn0.weight\", \"encoder._blocks.24._bn0.bias\", \"encoder._blocks.24._bn0.running_mean\", \"encoder._blocks.24._bn0.running_var\", \"encoder._blocks.24._depthwise_conv.weight\", \"encoder._blocks.24._bn1.weight\", \"encoder._blocks.24._bn1.bias\", \"encoder._blocks.24._bn1.running_mean\", \"encoder._blocks.24._bn1.running_var\", \"encoder._blocks.24._se_reduce.weight\", \"encoder._blocks.24._se_reduce.bias\", \"encoder._blocks.24._se_expand.weight\", \"encoder._blocks.24._se_expand.bias\", \"encoder._blocks.24._project_conv.weight\", \"encoder._blocks.24._bn2.weight\", \"encoder._blocks.24._bn2.bias\", \"encoder._blocks.24._bn2.running_mean\", \"encoder._blocks.24._bn2.running_var\", \"encoder._blocks.25._expand_conv.weight\", \"encoder._blocks.25._bn0.weight\", \"encoder._blocks.25._bn0.bias\", \"encoder._blocks.25._bn0.running_mean\", \"encoder._blocks.25._bn0.running_var\", \"encoder._blocks.25._depthwise_conv.weight\", \"encoder._blocks.25._bn1.weight\", \"encoder._blocks.25._bn1.bias\", \"encoder._blocks.25._bn1.running_mean\", \"encoder._blocks.25._bn1.running_var\", \"encoder._blocks.25._se_reduce.weight\", \"encoder._blocks.25._se_reduce.bias\", \"encoder._blocks.25._se_expand.weight\", \"encoder._blocks.25._se_expand.bias\", \"encoder._blocks.25._project_conv.weight\", \"encoder._blocks.25._bn2.weight\", \"encoder._blocks.25._bn2.bias\", \"encoder._blocks.25._bn2.running_mean\", \"encoder._blocks.25._bn2.running_var\", \"encoder._blocks.26._expand_conv.weight\", \"encoder._blocks.26._bn0.weight\", \"encoder._blocks.26._bn0.bias\", \"encoder._blocks.26._bn0.running_mean\", \"encoder._blocks.26._bn0.running_var\", \"encoder._blocks.26._depthwise_conv.weight\", \"encoder._blocks.26._bn1.weight\", \"encoder._blocks.26._bn1.bias\", \"encoder._blocks.26._bn1.running_mean\", \"encoder._blocks.26._bn1.running_var\", \"encoder._blocks.26._se_reduce.weight\", \"encoder._blocks.26._se_reduce.bias\", \"encoder._blocks.26._se_expand.weight\", \"encoder._blocks.26._se_expand.bias\", \"encoder._blocks.26._project_conv.weight\", \"encoder._blocks.26._bn2.weight\", \"encoder._blocks.26._bn2.bias\", \"encoder._blocks.26._bn2.running_mean\", \"encoder._blocks.26._bn2.running_var\", \"encoder._blocks.27._expand_conv.weight\", \"encoder._blocks.27._bn0.weight\", \"encoder._blocks.27._bn0.bias\", \"encoder._blocks.27._bn0.running_mean\", \"encoder._blocks.27._bn0.running_var\", \"encoder._blocks.27._depthwise_conv.weight\", \"encoder._blocks.27._bn1.weight\", \"encoder._blocks.27._bn1.bias\", \"encoder._blocks.27._bn1.running_mean\", \"encoder._blocks.27._bn1.running_var\", \"encoder._blocks.27._se_reduce.weight\", \"encoder._blocks.27._se_reduce.bias\", \"encoder._blocks.27._se_expand.weight\", \"encoder._blocks.27._se_expand.bias\", \"encoder._blocks.27._project_conv.weight\", \"encoder._blocks.27._bn2.weight\", \"encoder._blocks.27._bn2.bias\", \"encoder._blocks.27._bn2.running_mean\", \"encoder._blocks.27._bn2.running_var\", \"encoder._blocks.28._expand_conv.weight\", \"encoder._blocks.28._bn0.weight\", \"encoder._blocks.28._bn0.bias\", \"encoder._blocks.28._bn0.running_mean\", \"encoder._blocks.28._bn0.running_var\", \"encoder._blocks.28._depthwise_conv.weight\", \"encoder._blocks.28._bn1.weight\", \"encoder._blocks.28._bn1.bias\", \"encoder._blocks.28._bn1.running_mean\", \"encoder._blocks.28._bn1.running_var\", \"encoder._blocks.28._se_reduce.weight\", \"encoder._blocks.28._se_reduce.bias\", \"encoder._blocks.28._se_expand.weight\", \"encoder._blocks.28._se_expand.bias\", \"encoder._blocks.28._project_conv.weight\", \"encoder._blocks.28._bn2.weight\", \"encoder._blocks.28._bn2.bias\", \"encoder._blocks.28._bn2.running_mean\", \"encoder._blocks.28._bn2.running_var\", \"encoder._blocks.29._expand_conv.weight\", \"encoder._blocks.29._bn0.weight\", \"encoder._blocks.29._bn0.bias\", \"encoder._blocks.29._bn0.running_mean\", \"encoder._blocks.29._bn0.running_var\", \"encoder._blocks.29._depthwise_conv.weight\", \"encoder._blocks.29._bn1.weight\", \"encoder._blocks.29._bn1.bias\", \"encoder._blocks.29._bn1.running_mean\", \"encoder._blocks.29._bn1.running_var\", \"encoder._blocks.29._se_reduce.weight\", \"encoder._blocks.29._se_reduce.bias\", \"encoder._blocks.29._se_expand.weight\", \"encoder._blocks.29._se_expand.bias\", \"encoder._blocks.29._project_conv.weight\", \"encoder._blocks.29._bn2.weight\", \"encoder._blocks.29._bn2.bias\", \"encoder._blocks.29._bn2.running_mean\", \"encoder._blocks.29._bn2.running_var\", \"encoder._blocks.30._expand_conv.weight\", \"encoder._blocks.30._bn0.weight\", \"encoder._blocks.30._bn0.bias\", \"encoder._blocks.30._bn0.running_mean\", \"encoder._blocks.30._bn0.running_var\", \"encoder._blocks.30._depthwise_conv.weight\", \"encoder._blocks.30._bn1.weight\", \"encoder._blocks.30._bn1.bias\", \"encoder._blocks.30._bn1.running_mean\", \"encoder._blocks.30._bn1.running_var\", \"encoder._blocks.30._se_reduce.weight\", \"encoder._blocks.30._se_reduce.bias\", \"encoder._blocks.30._se_expand.weight\", \"encoder._blocks.30._se_expand.bias\", \"encoder._blocks.30._project_conv.weight\", \"encoder._blocks.30._bn2.weight\", \"encoder._blocks.30._bn2.bias\", \"encoder._blocks.30._bn2.running_mean\", \"encoder._blocks.30._bn2.running_var\", \"encoder._blocks.31._expand_conv.weight\", \"encoder._blocks.31._bn0.weight\", \"encoder._blocks.31._bn0.bias\", \"encoder._blocks.31._bn0.running_mean\", \"encoder._blocks.31._bn0.running_var\", \"encoder._blocks.31._depthwise_conv.weight\", \"encoder._blocks.31._bn1.weight\", \"encoder._blocks.31._bn1.bias\", \"encoder._blocks.31._bn1.running_mean\", \"encoder._blocks.31._bn1.running_var\", \"encoder._blocks.31._se_reduce.weight\", \"encoder._blocks.31._se_reduce.bias\", \"encoder._blocks.31._se_expand.weight\", \"encoder._blocks.31._se_expand.bias\", \"encoder._blocks.31._project_conv.weight\", \"encoder._blocks.31._bn2.weight\", \"encoder._blocks.31._bn2.bias\", \"encoder._blocks.31._bn2.running_mean\", \"encoder._blocks.31._bn2.running_var\", \"encoder._conv_head.weight\", \"encoder._bn1.weight\", \"encoder._bn1.bias\", \"encoder._bn1.running_mean\", \"encoder._bn1.running_var\". \n\tUnexpected key(s) in state_dict: \"encoder.conv1.weight\", \"encoder.bn1.weight\", \"encoder.bn1.bias\", \"encoder.bn1.running_mean\", \"encoder.bn1.running_var\", \"encoder.bn1.num_batches_tracked\", \"encoder.layer1.0.conv1.weight\", \"encoder.layer1.0.bn1.weight\", \"encoder.layer1.0.bn1.bias\", \"encoder.layer1.0.bn1.running_mean\", \"encoder.layer1.0.bn1.running_var\", \"encoder.layer1.0.bn1.num_batches_tracked\", \"encoder.layer1.0.conv2.weight\", \"encoder.layer1.0.bn2.weight\", \"encoder.layer1.0.bn2.bias\", \"encoder.layer1.0.bn2.running_mean\", \"encoder.layer1.0.bn2.running_var\", \"encoder.layer1.0.bn2.num_batches_tracked\", \"encoder.layer1.0.conv3.weight\", \"encoder.layer1.0.bn3.weight\", \"encoder.layer1.0.bn3.bias\", \"encoder.layer1.0.bn3.running_mean\", \"encoder.layer1.0.bn3.running_var\", \"encoder.layer1.0.bn3.num_batches_tracked\", \"encoder.layer1.0.downsample.0.weight\", \"encoder.layer1.0.downsample.1.weight\", \"encoder.layer1.0.downsample.1.bias\", \"encoder.layer1.0.downsample.1.running_mean\", \"encoder.layer1.0.downsample.1.running_var\", \"encoder.layer1.0.downsample.1.num_batches_tracked\", \"encoder.layer1.1.conv1.weight\", \"encoder.layer1.1.bn1.weight\", \"encoder.layer1.1.bn1.bias\", \"encoder.layer1.1.bn1.running_mean\", \"encoder.layer1.1.bn1.running_var\", \"encoder.layer1.1.bn1.num_batches_tracked\", \"encoder.layer1.1.conv2.weight\", \"encoder.layer1.1.bn2.weight\", \"encoder.layer1.1.bn2.bias\", \"encoder.layer1.1.bn2.running_mean\", \"encoder.layer1.1.bn2.running_var\", \"encoder.layer1.1.bn2.num_batches_tracked\", \"encoder.layer1.1.conv3.weight\", \"encoder.layer1.1.bn3.weight\", \"encoder.layer1.1.bn3.bias\", \"encoder.layer1.1.bn3.running_mean\", \"encoder.layer1.1.bn3.running_var\", \"encoder.layer1.1.bn3.num_batches_tracked\", \"encoder.layer1.2.conv1.weight\", \"encoder.layer1.2.bn1.weight\", \"encoder.layer1.2.bn1.bias\", \"encoder.layer1.2.bn1.running_mean\", \"encoder.layer1.2.bn1.running_var\", \"encoder.layer1.2.bn1.num_batches_tracked\", \"encoder.layer1.2.conv2.weight\", \"encoder.layer1.2.bn2.weight\", \"encoder.layer1.2.bn2.bias\", \"encoder.layer1.2.bn2.running_mean\", \"encoder.layer1.2.bn2.running_var\", \"encoder.layer1.2.bn2.num_batches_tracked\", \"encoder.layer1.2.conv3.weight\", \"encoder.layer1.2.bn3.weight\", \"encoder.layer1.2.bn3.bias\", \"encoder.layer1.2.bn3.running_mean\", \"encoder.layer1.2.bn3.running_var\", \"encoder.layer1.2.bn3.num_batches_tracked\", \"encoder.layer2.0.conv1.weight\", \"encoder.layer2.0.bn1.weight\", \"encoder.layer2.0.bn1.bias\", \"encoder.layer2.0.bn1.running_mean\", \"encoder.layer2.0.bn1.running_var\", \"encoder.layer2.0.bn1.num_batches_tracked\", \"encoder.layer2.0.conv2.weight\", \"encoder.layer2.0.bn2.weight\", \"encoder.layer2.0.bn2.bias\", \"encoder.layer2.0.bn2.running_mean\", \"encoder.layer2.0.bn2.running_var\", \"encoder.layer2.0.bn2.num_batches_tracked\", \"encoder.layer2.0.conv3.weight\", \"encoder.layer2.0.bn3.weight\", \"encoder.layer2.0.bn3.bias\", \"encoder.layer2.0.bn3.running_mean\", \"encoder.layer2.0.bn3.running_var\", \"encoder.layer2.0.bn3.num_batches_tracked\", \"encoder.layer2.0.downsample.0.weight\", \"encoder.layer2.0.downsample.1.weight\", \"encoder.layer2.0.downsample.1.bias\", \"encoder.layer2.0.downsample.1.running_mean\", \"encoder.layer2.0.downsample.1.running_var\", \"encoder.layer2.0.downsample.1.num_batches_tracked\", \"encoder.layer2.1.conv1.weight\", \"encoder.layer2.1.bn1.weight\", \"encoder.layer2.1.bn1.bias\", \"encoder.layer2.1.bn1.running_mean\", \"encoder.layer2.1.bn1.running_var\", \"encoder.layer2.1.bn1.num_batches_tracked\", \"encoder.layer2.1.conv2.weight\", \"encoder.layer2.1.bn2.weight\", \"encoder.layer2.1.bn2.bias\", \"encoder.layer2.1.bn2.running_mean\", \"encoder.layer2.1.bn2.running_var\", \"encoder.layer2.1.bn2.num_batches_tracked\", \"encoder.layer2.1.conv3.weight\", \"encoder.layer2.1.bn3.weight\", \"encoder.layer2.1.bn3.bias\", \"encoder.layer2.1.bn3.running_mean\", \"encoder.layer2.1.bn3.running_var\", \"encoder.layer2.1.bn3.num_batches_tracked\", \"encoder.layer2.2.conv1.weight\", \"encoder.layer2.2.bn1.weight\", \"encoder.layer2.2.bn1.bias\", \"encoder.layer2.2.bn1.running_mean\", \"encoder.layer2.2.bn1.running_var\", \"encoder.layer2.2.bn1.num_batches_tracked\", \"encoder.layer2.2.conv2.weight\", \"encoder.layer2.2.bn2.weight\", \"encoder.layer2.2.bn2.bias\", \"encoder.layer2.2.bn2.running_mean\", \"encoder.layer2.2.bn2.running_var\", \"encoder.layer2.2.bn2.num_batches_tracked\", \"encoder.layer2.2.conv3.weight\", \"encoder.layer2.2.bn3.weight\", \"encoder.layer2.2.bn3.bias\", \"encoder.layer2.2.bn3.running_mean\", \"encoder.layer2.2.bn3.running_var\", \"encoder.layer2.2.bn3.num_batches_tracked\", \"encoder.layer2.3.conv1.weight\", \"encoder.layer2.3.bn1.weight\", \"encoder.layer2.3.bn1.bias\", \"encoder.layer2.3.bn1.running_mean\", \"encoder.layer2.3.bn1.running_var\", \"encoder.layer2.3.bn1.num_batches_tracked\", \"encoder.layer2.3.conv2.weight\", \"encoder.layer2.3.bn2.weight\", \"encoder.layer2.3.bn2.bias\", \"encoder.layer2.3.bn2.running_mean\", \"encoder.layer2.3.bn2.running_var\", \"encoder.layer2.3.bn2.num_batches_tracked\", \"encoder.layer2.3.conv3.weight\", \"encoder.layer2.3.bn3.weight\", \"encoder.layer2.3.bn3.bias\", \"encoder.layer2.3.bn3.running_mean\", \"encoder.layer2.3.bn3.running_var\", \"encoder.layer2.3.bn3.num_batches_tracked\", \"encoder.layer3.0.conv1.weight\", \"encoder.layer3.0.bn1.weight\", \"encoder.layer3.0.bn1.bias\", \"encoder.layer3.0.bn1.running_mean\", \"encoder.layer3.0.bn1.running_var\", \"encoder.layer3.0.bn1.num_batches_tracked\", \"encoder.layer3.0.conv2.weight\", \"encoder.layer3.0.bn2.weight\", \"encoder.layer3.0.bn2.bias\", \"encoder.layer3.0.bn2.running_mean\", \"encoder.layer3.0.bn2.running_var\", \"encoder.layer3.0.bn2.num_batches_tracked\", \"encoder.layer3.0.conv3.weight\", \"encoder.layer3.0.bn3.weight\", \"encoder.layer3.0.bn3.bias\", \"encoder.layer3.0.bn3.running_mean\", \"encoder.layer3.0.bn3.running_var\", \"encoder.layer3.0.bn3.num_batches_tracked\", \"encoder.layer3.0.downsample.0.weight\", \"encoder.layer3.0.downsample.1.weight\", \"encoder.layer3.0.downsample.1.bias\", \"encoder.layer3.0.downsample.1.running_mean\", \"encoder.layer3.0.downsample.1.running_var\", \"encoder.layer3.0.downsample.1.num_batches_tracked\", \"encoder.layer3.1.conv1.weight\", \"encoder.layer3.1.bn1.weight\", \"encoder.layer3.1.bn1.bias\", \"encoder.layer3.1.bn1.running_mean\", \"encoder.layer3.1.bn1.running_var\", \"encoder.layer3.1.bn1.num_batches_tracked\", \"encoder.layer3.1.conv2.weight\", \"encoder.layer3.1.bn2.weight\", \"encoder.layer3.1.bn2.bias\", \"encoder.layer3.1.bn2.running_mean\", \"encoder.layer3.1.bn2.running_var\", \"encoder.layer3.1.bn2.num_batches_tracked\", \"encoder.layer3.1.conv3.weight\", \"encoder.layer3.1.bn3.weight\", \"encoder.layer3.1.bn3.bias\", \"encoder.layer3.1.bn3.running_mean\", \"encoder.layer3.1.bn3.running_var\", \"encoder.layer3.1.bn3.num_batches_tracked\", \"encoder.layer3.2.conv1.weight\", \"encoder.layer3.2.bn1.weight\", \"encoder.layer3.2.bn1.bias\", \"encoder.layer3.2.bn1.running_mean\", \"encoder.layer3.2.bn1.running_var\", \"encoder.layer3.2.bn1.num_batches_tracked\", \"encoder.layer3.2.conv2.weight\", \"encoder.layer3.2.bn2.weight\", \"encoder.layer3.2.bn2.bias\", \"encoder.layer3.2.bn2.running_mean\", \"encoder.layer3.2.bn2.running_var\", \"encoder.layer3.2.bn2.num_batches_tracked\", \"encoder.layer3.2.conv3.weight\", \"encoder.layer3.2.bn3.weight\", \"encoder.layer3.2.bn3.bias\", \"encoder.layer3.2.bn3.running_mean\", \"encoder.layer3.2.bn3.running_var\", \"encoder.layer3.2.bn3.num_batches_tracked\", \"encoder.layer3.3.conv1.weight\", \"encoder.layer3.3.bn1.weight\", \"encoder.layer3.3.bn1.bias\", \"encoder.layer3.3.bn1.running_mean\", \"encoder.layer3.3.bn1.running_var\", \"encoder.layer3.3.bn1.num_batches_tracked\", \"encoder.layer3.3.conv2.weight\", \"encoder.layer3.3.bn2.weight\", \"encoder.layer3.3.bn2.bias\", \"encoder.layer3.3.bn2.running_mean\", \"encoder.layer3.3.bn2.running_var\", \"encoder.layer3.3.bn2.num_batches_tracked\", \"encoder.layer3.3.conv3.weight\", \"encoder.layer3.3.bn3.weight\", \"encoder.layer3.3.bn3.bias\", \"encoder.layer3.3.bn3.running_mean\", \"encoder.layer3.3.bn3.running_var\", \"encoder.layer3.3.bn3.num_batches_tracked\", \"encoder.layer3.4.conv1.weight\", \"encoder.layer3.4.bn1.weight\", \"encoder.layer3.4.bn1.bias\", \"encoder.layer3.4.bn1.running_mean\", \"encoder.layer3.4.bn1.running_var\", \"encoder.layer3.4.bn1.num_batches_tracked\", \"encoder.layer3.4.conv2.weight\", \"encoder.layer3.4.bn2.weight\", \"encoder.layer3.4.bn2.bias\", \"encoder.layer3.4.bn2.running_mean\", \"encoder.layer3.4.bn2.running_var\", \"encoder.layer3.4.bn2.num_batches_tracked\", \"encoder.layer3.4.conv3.weight\", \"encoder.layer3.4.bn3.weight\", \"encoder.layer3.4.bn3.bias\", \"encoder.layer3.4.bn3.running_mean\", \"encoder.layer3.4.bn3.running_var\", \"encoder.layer3.4.bn3.num_batches_tracked\", \"encoder.layer3.5.conv1.weight\", \"encoder.layer3.5.bn1.weight\", \"encoder.layer3.5.bn1.bias\", \"encoder.layer3.5.bn1.running_mean\", \"encoder.layer3.5.bn1.running_var\", \"encoder.layer3.5.bn1.num_batches_tracked\", \"encoder.layer3.5.conv2.weight\", \"encoder.layer3.5.bn2.weight\", \"encoder.layer3.5.bn2.bias\", \"encoder.layer3.5.bn2.running_mean\", \"encoder.layer3.5.bn2.running_var\", \"encoder.layer3.5.bn2.num_batches_tracked\", \"encoder.layer3.5.conv3.weight\", \"encoder.layer3.5.bn3.weight\", \"encoder.layer3.5.bn3.bias\", \"encoder.layer3.5.bn3.running_mean\", \"encoder.layer3.5.bn3.running_var\", \"encoder.layer3.5.bn3.num_batches_tracked\", \"encoder.layer4.0.conv1.weight\", \"encoder.layer4.0.bn1.weight\", \"encoder.layer4.0.bn1.bias\", \"encoder.layer4.0.bn1.running_mean\", \"encoder.layer4.0.bn1.running_var\", \"encoder.layer4.0.bn1.num_batches_tracked\", \"encoder.layer4.0.conv2.weight\", \"encoder.layer4.0.bn2.weight\", \"encoder.layer4.0.bn2.bias\", \"encoder.layer4.0.bn2.running_mean\", \"encoder.layer4.0.bn2.running_var\", \"encoder.layer4.0.bn2.num_batches_tracked\", \"encoder.layer4.0.conv3.weight\", \"encoder.layer4.0.bn3.weight\", \"encoder.layer4.0.bn3.bias\", \"encoder.layer4.0.bn3.running_mean\", \"encoder.layer4.0.bn3.running_var\", \"encoder.layer4.0.bn3.num_batches_tracked\", \"encoder.layer4.0.downsample.0.weight\", \"encoder.layer4.0.downsample.1.weight\", \"encoder.layer4.0.downsample.1.bias\", \"encoder.layer4.0.downsample.1.running_mean\", \"encoder.layer4.0.downsample.1.running_var\", \"encoder.layer4.0.downsample.1.num_batches_tracked\", \"encoder.layer4.1.conv1.weight\", \"encoder.layer4.1.bn1.weight\", \"encoder.layer4.1.bn1.bias\", \"encoder.layer4.1.bn1.running_mean\", \"encoder.layer4.1.bn1.running_var\", \"encoder.layer4.1.bn1.num_batches_tracked\", \"encoder.layer4.1.conv2.weight\", \"encoder.layer4.1.bn2.weight\", \"encoder.layer4.1.bn2.bias\", \"encoder.layer4.1.bn2.running_mean\", \"encoder.layer4.1.bn2.running_var\", \"encoder.layer4.1.bn2.num_batches_tracked\", \"encoder.layer4.1.conv3.weight\", \"encoder.layer4.1.bn3.weight\", \"encoder.layer4.1.bn3.bias\", \"encoder.layer4.1.bn3.running_mean\", \"encoder.layer4.1.bn3.running_var\", \"encoder.layer4.1.bn3.num_batches_tracked\", \"encoder.layer4.2.conv1.weight\", \"encoder.layer4.2.bn1.weight\", \"encoder.layer4.2.bn1.bias\", \"encoder.layer4.2.bn1.running_mean\", \"encoder.layer4.2.bn1.running_var\", \"encoder.layer4.2.bn1.num_batches_tracked\", \"encoder.layer4.2.conv2.weight\", \"encoder.layer4.2.bn2.weight\", \"encoder.layer4.2.bn2.bias\", \"encoder.layer4.2.bn2.running_mean\", \"encoder.layer4.2.bn2.running_var\", \"encoder.layer4.2.bn2.num_batches_tracked\", \"encoder.layer4.2.conv3.weight\", \"encoder.layer4.2.bn3.weight\", \"encoder.layer4.2.bn3.bias\", \"encoder.layer4.2.bn3.running_mean\", \"encoder.layer4.2.bn3.running_var\", \"encoder.layer4.2.bn3.num_batches_tracked\". \n\tsize mismatch for decoder.blocks.0.conv1.0.weight: copying a param with shape torch.Size([256, 3072, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 608, 3, 3]).\n\tsize mismatch for decoder.blocks.1.conv1.0.weight: copying a param with shape torch.Size([128, 768, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 312, 3, 3]).\n\tsize mismatch for decoder.blocks.2.conv1.0.weight: copying a param with shape torch.Size([64, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 160, 3, 3]).\n\tsize mismatch for decoder.blocks.3.conv1.0.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 112, 3, 3])."
                    ]
                }
            ],
            "source": [
                "# load best saved model checkpoint from the current ru\n",
                "\n",
                "import dataset\n",
                "import utils\n",
                "import config\n",
                "\n",
                "\n",
                "model_path=\"/home/daniel/deepvalve/src/segmentation/segmentation_results_exploitation/sandy-sweep-8best_model.pth\"\n",
                "\n",
                "# if os.path.exists('../data/models/'):\n",
                "model.load_state_dict(torch.load(model_path))\n",
                "model.eval()\n",
                "\n",
                "    \n",
                "\n",
                "# load best saved model checkpoint from previous commit (if present)\n",
                "# elif os.path.exists('../input//unet-with-pretrained-resnet50-encoder-pytorch/best_model.pth'):\n",
                "#     best_model = torch.load('../input//unet-with-pretrained-resnet50-encoder-pytorch/best_model.pth', map_location=DEVICE)\n",
                "#     print('Loaded UNet model from a previous commit.')\n",
                "# create test dataloader (with preprocessing operation: to_tensor(...))\n",
                "test_dataset = dataset.heartdataset(\n",
                "    x_test_dir,\n",
                "    y_test_dir,\n",
                "    augmentation=utils.get_validation_augmentation(),\n",
                "    preprocessing=utils.get_preprocessing(preprocessing_fn),\n",
                "    class_rgb_values=select_class_rgb_values,\n",
                ")\n",
                "\n",
                "test_dataloader = DataLoader(test_dataset)\n",
                "\n",
                "# test dataset for visualization (without preprocessing transformations)\n",
                "test_dataset_vis = dataset.heartdataset(\n",
                "    x_test_dir, y_test_dir,\n",
                "    augmentation=utils.get_validation_augmentation(),\n",
                "    class_rgb_values=select_class_rgb_values,\n",
                ")\n",
                "\n",
                "# get a random test image/mask index\n",
                "random_idx = random.randint(0, len(test_dataset_vis)-1)\n",
                "image, mask = test_dataset_vis[random_idx]\n",
                "\n",
                "utils.visualize(\n",
                "    original_image = image,\n",
                "    ground_truth_mask = utils.colour_code_segmentation(utils.reverse_one_hot(mask), select_class_rgb_values),\n",
                "    one_hot_encoded_mask = utils.reverse_one_hot(mask)\n",
                ")\n",
                "# Center crop padded image / mask to original image dims\n",
                "def crop_image(image, target_image_dims=[448,448,3]):\n",
                "\n",
                "    target_size = target_image_dims[0]\n",
                "    image_size = len(image)\n",
                "    padding = (image_size - target_size) // 2\n",
                "\n",
                "    return image[\n",
                "        padding:image_size - padding,\n",
                "        padding:image_size - padding,\n",
                "        :,\n",
                "    ]\n",
                "\n",
                "sample_preds_folder = 'sample_predictions/'\n",
                "if not os.path.exists(sample_preds_folder):\n",
                "    os.makedirs(sample_preds_folder)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Sample"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for idx in range(len(test_dataset)):\n",
                "\n",
                "    image, gt_mask = test_dataset[idx]\n",
                "    image_vis = crop_image(test_dataset_vis[idx][0].astype('uint8'))\n",
                "    x_tensor = torch.from_numpy(image).to(\"cpu\").unsqueeze(0)\n",
                "    # Predict test image\n",
                "    pred_mask = model(x_tensor)\n",
                "    pred_mask = pred_mask.detach().squeeze().cpu().numpy()\n",
                "    # Convert pred_mask from `CHW` format to `HWC` format\n",
                "    pred_mask = np.transpose(pred_mask,(1,2,0))\n",
                "    # Get prediction channel corresponding to building\n",
                "    pred_building_heatmap = pred_mask[:,:,select_classes.index('leaflet')]\n",
                "    pred_mask = crop_image(utils.colour_code_segmentation(utils.reverse_one_hot(pred_mask), select_class_rgb_values))\n",
                "    # Convert gt_mask from `CHW` format to `HWC` format\n",
                "    gt_mask = np.transpose(gt_mask,(1,2,0))\n",
                "    gt_mask = crop_image(utils.colour_code_segmentation(utils.reverse_one_hot(gt_mask), select_class_rgb_values))\n",
                "\n",
                "    ## to save them\n",
                "    # cv2.imwrite(os.path.join(sample_preds_folder, f\"sample_pred_{idx}.png\"), np.hstack([image_vis, gt_mask, pred_mask])[:,:,::-1])  \n",
                "\n",
                "    utils.visualize(\n",
                "        original_image = image_vis,\n",
                "        ground_truth_mask = gt_mask,\n",
                "        predicted_mask = pred_mask,\n",
                "        predicted_leaflet_heatmap = pred_building_heatmap\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.11.4 ('deepvalve')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "7e425331017aa2792a787d47e87be0499f98464e06ac26bef7ff6ffb74fe506b"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
